{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Fusion Retrieval: Combining Vector and Keyword Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "import fitz\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트 내용을 추출합니다.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일 경로\n",
    "        \n",
    "    Returns:\n",
    "        str: 추출된 텍스트 내용\n",
    "    \"\"\"\n",
    "    print(f\"{pdf_path}에서 텍스트 추출 중...\")  # 현재 처리 중인 PDF 경로 출력\n",
    "    pdf_document = fitz.open(pdf_path)  # PyMuPDF를 사용하여 PDF 파일 열기\n",
    "    text = \"\"  # 추출된 텍스트를 저장할 빈 문자열 초기화\n",
    "    \n",
    "    # PDF의 각 페이지를 순회하며 텍스트 추출\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_num]  # 페이지 객체 가져오기\n",
    "        text += page.get_text()  # 해당 페이지에서 텍스트를 추출하고 누적\n",
    "    \n",
    "    return text  # 최종적으로 추출된 전체 텍스트 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    텍스트를 오버랩이 포함된 청크로 분할합니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 분할할 입력 텍스트\n",
    "        chunk_size (int): 각 청크의 문자 수\n",
    "        chunk_overlap (int): 청크 간 중첩 문자 수\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: 텍스트와 메타데이터를 포함한 청크 리스트\n",
    "    \"\"\"\n",
    "    chunks = []  # 청크 데이터를 저장할 리스트 초기화\n",
    "\n",
    "    # 지정된 크기와 오버랩에 따라 텍스트를 순회하며 청크 생성\n",
    "    for i in range(0, len(text), chunk_size - chunk_overlap):\n",
    "        chunk = text[i:i + chunk_size]  # 현재 위치에서 chunk_size만큼 자르기\n",
    "        if chunk:  # 비어 있지 않은 청크만 추가\n",
    "            chunk_data = {\n",
    "                \"text\": chunk,  # 청크 텍스트\n",
    "                \"metadata\": {\n",
    "                    \"start_char\": i,               # 청크 시작 위치 (문자 인덱스)\n",
    "                    \"end_char\": i + len(chunk)     # 청크 종료 위치 (문자 인덱스)\n",
    "                }\n",
    "            }\n",
    "            chunks.append(chunk_data)  # 청크 데이터를 리스트에 추가\n",
    "\n",
    "    print(f\"{len(chunks)}개의 텍스트 청크가 생성되었습니다\")  # 생성된 청크 수 출력\n",
    "    return chunks  # 청크 리스트 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    텍스트에서 불필요한 공백 및 특수 문자를 제거하여 정리합니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 정리할 입력 텍스트\n",
    "\n",
    "    Returns:\n",
    "        str: 정리된 텍스트\n",
    "    \"\"\"\n",
    "    # 여러 개의 공백 문자(스페이스, 줄바꿈, 탭 등)를 하나의 공백으로 치환\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # OCR 오류로 생긴 이스케이프된 탭(\\t)과 줄바꿈(\\n) 문자를 공백으로 치환\n",
    "    text = text.replace('\\\\t', ' ')\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    \n",
    "    # 앞뒤 공백 제거 및 단어 사이 공백을 하나로 통일\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_embeddings(texts, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    주어진 텍스트(들)에 대해 임베딩을 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        texts (str 또는 List[str]): 입력 텍스트 또는 텍스트 리스트\n",
    "        model (str): 사용할 임베딩 모델 이름\n",
    "        \n",
    "    Returns:\n",
    "        List[List[float]] 또는 List[float]: 생성된 임베딩 벡터(들)\n",
    "    \"\"\"\n",
    "    # 문자열과 리스트 둘 다 처리 가능하도록 통일\n",
    "    input_texts = texts if isinstance(texts, list) else [texts]\n",
    "    \n",
    "    # API 호출 제한을 고려한 배치 처리\n",
    "    batch_size = 100\n",
    "    all_embeddings = []  # 전체 임베딩 결과 저장 리스트\n",
    "    \n",
    "    # 배치 단위로 입력 텍스트 처리\n",
    "    for i in range(0, len(input_texts), batch_size):\n",
    "        batch = input_texts[i:i + batch_size]  # 현재 배치 텍스트 가져오기\n",
    "        \n",
    "        # 해당 배치에 대해 임베딩 생성 요청\n",
    "        response = client.embeddings.create(\n",
    "            model=model,\n",
    "            input=batch\n",
    "        )\n",
    "        \n",
    "        # 응답에서 임베딩 벡터 추출\n",
    "        batch_embeddings = [item.embedding for item in response.data]\n",
    "        all_embeddings.extend(batch_embeddings)  # 전체 임베딩 리스트에 추가\n",
    "    \n",
    "    # 입력이 문자열 하나였다면, 첫 번째 결과만 반환\n",
    "    if isinstance(texts, str):\n",
    "        return all_embeddings[0]\n",
    "    \n",
    "    # 리스트 입력인 경우 전체 임베딩 리스트 반환\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    NumPy를 사용한 간단한 벡터 저장소 구현입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.vectors = []  # 임베딩 벡터를 저장할 리스트\n",
    "        self.texts = []  # 텍스트 내용을 저장할 리스트\n",
    "        self.metadata = []  # 메타데이터를 저장할 리스트\n",
    "\n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        단일 항목을 벡터 저장소에 추가합니다.\n",
    "        \n",
    "        Args:\n",
    "            text (str): 텍스트 내용\n",
    "            embedding (List[float]): 임베딩 벡터\n",
    "            metadata (Dict, 선택): 추가 메타데이터\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))  # 임베딩 벡터 추가\n",
    "        self.texts.append(text)  # 텍스트 추가\n",
    "        self.metadata.append(metadata or {})  # 메타데이터 추가 (없으면 빈 딕셔너리)\n",
    "\n",
    "    def add_items(self, items, embeddings):\n",
    "        \"\"\"\n",
    "        여러 항목을 저장소에 일괄 추가합니다.\n",
    "        \n",
    "        Args:\n",
    "            items (List[Dict]): 텍스트 및 메타데이터가 포함된 항목 리스트\n",
    "            embeddings (List[List[float]]): 각 항목의 임베딩 벡터 리스트\n",
    "        \"\"\"\n",
    "        for i, (item, embedding) in enumerate(zip(items, embeddings)):\n",
    "            self.add_item(\n",
    "                text=item[\"text\"],  # 항목에서 텍스트 추출\n",
    "                embedding=embedding,  # 해당 임베딩 사용\n",
    "                metadata={**item.get(\"metadata\", {}), \"index\": i}  # 기존 메타데이터에 인덱스 추가\n",
    "            )\n",
    "\n",
    "    def similarity_search_with_scores(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        쿼리 임베딩과 가장 유사한 항목 k개를 유사도 점수와 함께 반환합니다.\n",
    "        \n",
    "        Args:\n",
    "            query_embedding (List[float]): 쿼리 임베딩 벡터\n",
    "            k (int): 반환할 유사 항목 수\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: 유사도 상위 k개의 항목 (텍스트, 메타데이터, 유사도 포함)\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []  # 벡터가 없으면 빈 리스트 반환\n",
    "\n",
    "        query_vector = np.array(query_embedding)  # 쿼리 벡터를 NumPy 배열로 변환\n",
    "        similarities = []\n",
    "\n",
    "        # 코사인 유사도 계산\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            similarity = cosine_similarity([query_vector], [vector])[0][0]\n",
    "            similarities.append((i, similarity))  # 인덱스와 유사도 저장\n",
    "\n",
    "        # 유사도 기준 내림차순 정렬\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 상위 k개 항목 반환\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],  # 해당 텍스트\n",
    "                \"metadata\": self.metadata[idx],  # 해당 메타데이터\n",
    "                \"similarity\": float(score)  # 유사도 점수\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_all_documents(self):\n",
    "        \"\"\"\n",
    "        저장소에 저장된 모든 문서를 가져옵니다.\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: 텍스트와 메타데이터가 포함된 문서 리스트\n",
    "        \"\"\"\n",
    "        return [{\"text\": text, \"metadata\": meta} for text, meta in zip(self.texts, self.metadata)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bm25_index(chunks):\n",
    "    \"\"\"\n",
    "    주어진 텍스트 청크들로부터 BM25 인덱스를 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        chunks (List[Dict]): 텍스트 청크 딕셔너리 리스트\n",
    "        \n",
    "    Returns:\n",
    "        BM25Okapi: 생성된 BM25 인덱스 객체\n",
    "    \"\"\"\n",
    "    # 각 청크에서 텍스트만 추출\n",
    "    texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    \n",
    "    # 공백 기준으로 각 문서를 토큰화\n",
    "    tokenized_docs = [text.split() for text in texts]\n",
    "    \n",
    "    # 토큰화된 문서를 이용해 BM25 인덱스 생성\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    \n",
    "    # 생성된 문서 개수 출력\n",
    "    print(f\"BM25 인덱스에 {len(texts)}개의 문서가 포함되었습니다\")\n",
    "    \n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bm25_search(bm25, chunks, query, k=5):\n",
    "    \"\"\"\n",
    "    BM25 인덱스를 사용하여 쿼리에 대한 검색을 수행합니다.\n",
    "    \n",
    "    Args:\n",
    "        bm25 (BM25Okapi): 생성된 BM25 인덱스 객체\n",
    "        chunks (List[Dict]): 텍스트 청크 리스트\n",
    "        query (str): 검색 쿼리 문자열\n",
    "        k (int): 반환할 결과 수 (Top-k)\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: 상위 k개의 결과와 BM25 점수를 포함한 리스트\n",
    "    \"\"\"\n",
    "    # 쿼리를 공백 기준으로 토큰화\n",
    "    query_tokens = query.split()\n",
    "    \n",
    "    # 쿼리 토큰에 대한 각 문서의 BM25 점수 계산\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    \n",
    "    results = []  # 점수와 함께 결과 저장할 리스트 초기화\n",
    "\n",
    "    # 각 점수와 해당 청크에 대해 순회\n",
    "    for i, score in enumerate(scores):\n",
    "        # 원본을 수정하지 않도록 메타데이터 복사\n",
    "        metadata = chunks[i].get(\"metadata\", {}).copy()\n",
    "        # 청크 인덱스를 메타데이터에 추가\n",
    "        metadata[\"index\"] = i\n",
    "\n",
    "        # 결과 딕셔너리에 텍스트, 메타데이터, 점수 포함\n",
    "        results.append({\n",
    "            \"text\": chunks[i][\"text\"],\n",
    "            \"metadata\": metadata,\n",
    "            \"bm25_score\": float(score)\n",
    "        })\n",
    "    \n",
    "    # BM25 점수를 기준으로 결과 내림차순 정렬\n",
    "    results.sort(key=lambda x: x[\"bm25_score\"], reverse=True)\n",
    "    \n",
    "    # 상위 k개의 결과 반환\n",
    "    return results[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fusion_retrieval(query, chunks, vector_store, bm25_index, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    벡터 기반 검색과 BM25 검색을 결합한 하이브리드 검색(fusion retrieval)을 수행합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 쿼리 문자열\n",
    "        chunks (List[Dict]): 원본 텍스트 청크 리스트\n",
    "        vector_store (SimpleVectorStore): 벡터 저장소\n",
    "        bm25_index (BM25Okapi): BM25 인덱스\n",
    "        k (int): 반환할 결과 수\n",
    "        alpha (float): 벡터 점수 가중치 (0~1), 나머지 (1-alpha)는 BM25 가중치\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 결합 점수 기준 상위 k개 검색 결과\n",
    "    \"\"\"\n",
    "    print(f\"쿼리에 대한 하이브리드 검색 수행 중: {query}\")\n",
    "    \n",
    "    epsilon = 1e-8  # 0으로 나누는 것을 방지하기 위한 아주 작은 수\n",
    "\n",
    "    # 쿼리 임베딩 생성 및 벡터 검색 수행\n",
    "    query_embedding = create_embeddings(query)\n",
    "    vector_results = vector_store.similarity_search_with_scores(\n",
    "        query_embedding, k=len(chunks)\n",
    "    )\n",
    "\n",
    "    # BM25 검색 수행\n",
    "    bm25_results = bm25_search(bm25_index, chunks, query, k=len(chunks))\n",
    "\n",
    "    # 결과 점수를 인덱스로 매핑 (index → score)\n",
    "    vector_scores_dict = {r[\"metadata\"][\"index\"]: r[\"similarity\"] for r in vector_results}\n",
    "    bm25_scores_dict = {r[\"metadata\"][\"index\"]: r[\"bm25_score\"] for r in bm25_results}\n",
    "\n",
    "    # 모든 문서에 대해 점수 결합 준비\n",
    "    all_docs = vector_store.get_all_documents()\n",
    "    combined_results = []\n",
    "\n",
    "    for i, doc in enumerate(all_docs):\n",
    "        vector_score = vector_scores_dict.get(i, 0.0)  # 없으면 0.0\n",
    "        bm25_score = bm25_scores_dict.get(i, 0.0)\n",
    "        combined_results.append({\n",
    "            \"text\": doc[\"text\"],\n",
    "            \"metadata\": doc[\"metadata\"],\n",
    "            \"vector_score\": vector_score,\n",
    "            \"bm25_score\": bm25_score,\n",
    "            \"index\": i\n",
    "        })\n",
    "\n",
    "    # 점수 배열로 변환 및 정규화 (0~1 사이로)\n",
    "    vector_scores = np.array([doc[\"vector_score\"] for doc in combined_results])\n",
    "    bm25_scores = np.array([doc[\"bm25_score\"] for doc in combined_results])\n",
    "\n",
    "    norm_vector_scores = (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores) + epsilon)\n",
    "    norm_bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores) + epsilon)\n",
    "\n",
    "    # 결합 점수 계산 (선형 가중 평균)\n",
    "    combined_scores = alpha * norm_vector_scores + (1 - alpha) * norm_bm25_scores\n",
    "\n",
    "    # 결합 점수를 결과에 추가\n",
    "    for i, score in enumerate(combined_scores):\n",
    "        combined_results[i][\"combined_score\"] = float(score)\n",
    "\n",
    "    # 결합 점수 기준으로 내림차순 정렬\n",
    "    combined_results.sort(key=lambda x: x[\"combined_score\"], reverse=True)\n",
    "\n",
    "    # 상위 k개 결과 반환\n",
    "    top_results = combined_results[:k]\n",
    "\n",
    "    print(f\"하이브리드 검색으로 {len(top_results)}개의 문서를 반환함\")\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_document(pdf_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    하이브리드 검색(fusion retrieval)을 위한 문서를 처리합니다.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일 경로\n",
    "        chunk_size (int): 각 청크의 문자 수\n",
    "        chunk_overlap (int): 청크 간 중첩 문자 수\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Dict], SimpleVectorStore, BM25Okapi]:\n",
    "            - 텍스트 청크 리스트\n",
    "            - 벡터 저장소(SimpleVectorStore)\n",
    "            - BM25 인덱스(BM25Okapi)\n",
    "    \"\"\"\n",
    "    # PDF 파일에서 텍스트 추출\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # 추출된 텍스트를 정리 (공백, 특수문자 제거)\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # 텍스트를 오버랩 포함 청크로 분할\n",
    "    chunks = chunk_text(cleaned_text, chunk_size, chunk_overlap)\n",
    "    \n",
    "    # 임베딩 생성을 위해 각 청크의 텍스트만 추출\n",
    "    chunk_texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    print(\"청크 임베딩 생성 중...\")\n",
    "\n",
    "    # 임베딩 생성\n",
    "    embeddings = create_embeddings(chunk_texts)\n",
    "\n",
    "    # 벡터 저장소 초기화 및 항목 추가\n",
    "    vector_store = SimpleVectorStore()\n",
    "    vector_store.add_items(chunks, embeddings)\n",
    "    print(f\"{len(chunks)}개의 항목이 벡터 저장소에 추가됨\")\n",
    "\n",
    "    # BM25 인덱스 생성\n",
    "    bm25_index = create_bm25_index(chunks)\n",
    "\n",
    "    # 청크, 벡터 저장소, BM25 인덱스 반환\n",
    "    return chunks, vector_store, bm25_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_response(query, context):\n",
    "    \"\"\"\n",
    "    주어진 쿼리와 문맥을 바탕으로 AI 응답을 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질문\n",
    "        context (str): 검색된 문서에서 제공된 문맥 정보\n",
    "\n",
    "    Returns반환값:\n",
    "        str: 생성된 응답\n",
    "    \"\"\"\n",
    "    # AI의 역할을 안내하는 시스템 프롬프트 정의\n",
    "    system_prompt = \"\"\"당신은 유용한 AI 어시스턴트입니다. 제공된 문맥을 바탕으로 사용자의 질문에 답변하세요. \n",
    "    문맥에 질문에 대한 충분한 정보가 없다면, 그 한계를 분명히 언급해 주세요.\"\"\"\n",
    "\n",
    "    # 사용자 프롬프트 구성 (문맥 + 질문)\n",
    "    user_prompt = f\"\"\"문맥:\n",
    "    {context}\n",
    "\n",
    "    질문: {query}\n",
    "\n",
    "    위의 문맥을 바탕으로 질문에 답변해 주세요.\"\"\"\n",
    "\n",
    "    # OpenAI API를 사용하여 응답 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # 사용할 모델 지정\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # 시스템 메시지 (AI 가이드)\n",
    "            {\"role\": \"user\", \"content\": user_prompt}  # 사용자 메시지 (문맥 + 질문)\n",
    "        ],\n",
    "        temperature=0.1  # 응답의 일관성을 높이기 위한 낮은 창의성 설정\n",
    "    )\n",
    "    \n",
    "    # 생성된 응답 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def answer_with_fusion_rag(query, chunks, vector_store, bm25_index, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Fusion RAG 기법을 사용하여 쿼리에 응답합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질문\n",
    "        chunks (List[Dict]): 텍스트 청크 리스트\n",
    "        vector_store (SimpleVectorStore): 벡터 저장소\n",
    "        bm25_index (BM25Okapi): BM25 인덱스\n",
    "        k (int): 검색할 문서 개수\n",
    "        alpha (float): 벡터 점수의 가중치 (0~1)\n",
    "\n",
    "    Returns:\n",
    "        Dict: 쿼리, 검색된 문서, 생성된 응답을 포함한 결과 딕셔너리\n",
    "    \"\"\"\n",
    "    # Fusion retrieval 방식으로 관련 문서 검색\n",
    "    retrieved_docs = fusion_retrieval(query, chunks, vector_store, bm25_index, k=k, alpha=alpha)\n",
    "\n",
    "    # 검색된 문서들의 텍스트를 구분선으로 연결하여 문맥 구성\n",
    "    context = \"\\n\\n---\\n\\n\".join([doc[\"text\"] for doc in retrieved_docs])\n",
    "\n",
    "    # 문맥과 쿼리를 기반으로 AI 응답 생성\n",
    "    response = generate_response(query, context)\n",
    "\n",
    "    # 쿼리, 검색 문서, 생성 응답을 딕셔너리로 반환\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": retrieved_docs,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Retrieval Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vector_only_rag(query, vector_store, k=5):\n",
    "    \"\"\"\n",
    "    벡터 기반 RAG만을 사용하여 쿼리에 응답합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질문\n",
    "        vector_store (SimpleVectorStore): 벡터 저장소\n",
    "        k (int): 검색할 문서 개수\n",
    "\n",
    "    Returns:\n",
    "        Dict: 쿼리, 검색 문서, 생성된 응답을 포함한 결과 딕셔너리\n",
    "    \"\"\"\n",
    "    # 쿼리 임베딩 생성\n",
    "    query_embedding = create_embeddings(query)\n",
    "    \n",
    "    # 벡터 유사도 기반으로 관련 문서 검색\n",
    "    retrieved_docs = vector_store.similarity_search_with_scores(query_embedding, k=k)\n",
    "    \n",
    "    # 검색된 문서들의 텍스트를 구분선으로 연결하여 문맥 구성\n",
    "    context = \"\\n\\n---\\n\\n\".join([doc[\"text\"] for doc in retrieved_docs])\n",
    "    \n",
    "    # 문맥을 기반으로 쿼리에 대한 응답 생성\n",
    "    response = generate_response(query, context)\n",
    "    \n",
    "    # 쿼리, 검색 문서, 응답을 딕셔너리 형태로 반환\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": retrieved_docs,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bm25_only_rag(query, chunks, bm25_index, k=5):\n",
    "    \"\"\"\n",
    "    BM25 기반 RAG만을 사용하여 쿼리에 응답합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str): 사용자 질문\n",
    "        chunks (List[Dict]): 텍스트 조각들\n",
    "        bm25_index (BM25Okapi): BM25 인덱스\n",
    "        k (int): 검색할 문서 개수\n",
    "\n",
    "    Returns:\n",
    "        Dict: 쿼리 결과\n",
    "    \"\"\"\n",
    "    # BM25 검색을 사용하여 문서를 검색합니다\n",
    "    retrieved_docs = bm25_search(bm25_index, chunks, query, k=k)\n",
    "    \n",
    "    # 검색된 문서의 텍스트를 구분자와 함께 연결하여 context를 생성합니다\n",
    "    context = \"\\n\\n---\\n\\n\".join([doc[\"text\"] for doc in retrieved_docs])\n",
    "    \n",
    "    # 쿼리와 구성된 context를 기반으로 응답을 생성합니다\n",
    "    response = generate_response(query, context)\n",
    "    \n",
    "    # 쿼리, 검색된 문서들, 생성된 응답을 반환합니다\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": retrieved_docs,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_retrieval_methods(query, chunks, vector_store, bm25_index, k=5, alpha=0.5, reference_answer=None):\n",
    "    \"\"\"\n",
    "    하나의 쿼리에 대해 다양한 검색(RAG) 방법을 비교합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str): 사용자 질문\n",
    "        chunks (List[Dict]): 텍스트 조각들\n",
    "        vector_store (SimpleVectorStore): 벡터 저장소\n",
    "        bm25_index (BM25Okapi): BM25 인덱스\n",
    "        k (int): 검색할 문서 개수\n",
    "        alpha (float): 벡터 기반 점수의 가중치 (결합 검색 시 사용)\n",
    "        reference_answer (str, optional): 정답 비교용 기준 응답\n",
    "\n",
    "    Returns:\n",
    "        Dict: 검색 방식별 결과 및 비교 내용\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== 쿼리에 대한 검색 방식 비교: {query} ===\\n\")\n",
    "    \n",
    "    # 벡터 기반 RAG 실행\n",
    "    print(\"\\n[1] 벡터 기반 RAG 실행 중...\")\n",
    "    vector_result = vector_only_rag(query, vector_store, k)\n",
    "    \n",
    "    # BM25 기반 RAG 실행\n",
    "    print(\"\\n[2] BM25 기반 RAG 실행 중...\")\n",
    "    bm25_result = bm25_only_rag(query, chunks, bm25_index, k)\n",
    "    \n",
    "    # 결합 기반(fusion) RAG 실행\n",
    "    print(\"\\n[3] 결합 기반 RAG 실행 중...\")\n",
    "    fusion_result = answer_with_fusion_rag(query, chunks, vector_store, bm25_index, k, alpha)\n",
    "    \n",
    "    # 서로 다른 검색 방식의 응답 비교\n",
    "    print(\"\\n[4] 응답 비교 중...\")\n",
    "    comparison = evaluate_responses(\n",
    "        query, \n",
    "        vector_result[\"response\"], \n",
    "        bm25_result[\"response\"], \n",
    "        fusion_result[\"response\"],\n",
    "        reference_answer\n",
    "    )\n",
    "    \n",
    "    # 비교 결과 반환\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"vector_result\": vector_result,\n",
    "        \"bm25_result\": bm25_result,\n",
    "        \"fusion_result\": fusion_result,\n",
    "        \"comparison\": comparison\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_responses(query, vector_response, bm25_response, fusion_response, reference_answer=None):\n",
    "    \"\"\"\n",
    "    서로 다른 검색 방식에서 생성된 응답들을 평가합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str): 사용자 질문\n",
    "        vector_response (str): 벡터 기반 RAG 응답\n",
    "        bm25_response (str): BM25 기반 RAG 응답\n",
    "        fusion_response (str): 결합 기반 RAG 응답\n",
    "        reference_answer (str, optional): 기준이 되는 정답 (선택 사항)\n",
    "\n",
    "    Returns:\n",
    "        str: 응답 평가 결과\n",
    "    \"\"\"\n",
    "    # 평가를 위한 시스템 프롬프트: 평가자의 역할과 평가 기준 안내\n",
    "    system_prompt = \"\"\"당신은 RAG 시스템의 전문가 평가자입니다. 아래의 세 가지 검색 방식에서 생성된 응답을 비교해 주세요:\n",
    "    1. 벡터 기반 검색: 의미적 유사성을 기반으로 문서를 검색합니다\n",
    "    2. BM25 키워드 기반 검색: 키워드 일치를 기반으로 문서를 검색합니다\n",
    "    3. 결합 기반 검색: 벡터 기반과 키워드 기반을 모두 결합하여 검색합니다\n",
    "\n",
    "    다음 기준에 따라 응답을 평가해 주세요:\n",
    "    - 질문과의 관련성\n",
    "    - 사실에 기반한 정확성\n",
    "    - 정보의 포괄성\n",
    "    - 명확성 및 일관성\n",
    "    \"\"\"\n",
    "\n",
    "    # 사용자 프롬프트: 질문과 세 가지 응답을 포함\n",
    "    user_prompt = f\"\"\"질문: {query}\n",
    "\n",
    "    벡터 기반 응답:\n",
    "    {vector_response}\n",
    "\n",
    "    BM25 키워드 기반 응답:\n",
    "    {bm25_response}\n",
    "\n",
    "    결합 기반 응답:\n",
    "    {fusion_response}\n",
    "    \"\"\"\n",
    "\n",
    "    # 기준 응답이 주어진 경우, 프롬프트에 추가\n",
    "    if reference_answer:\n",
    "        user_prompt += f\"\"\"\n",
    "            기준 응답:\n",
    "            {reference_answer}\n",
    "        \"\"\"\n",
    "\n",
    "    # 평가자에게 상세 비교를 요청하는 문장 추가\n",
    "    user_prompt += \"\"\"\n",
    "    위 세 응답에 대해 상세한 비교를 작성해 주세요. 이 쿼리에 가장 잘 대응한 방식은 무엇이며 그 이유는 무엇인가요?\n",
    "    각각의 응답 방식의 장점과 단점을 구체적으로 설명해 주세요.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # 사용할 모델 지정\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # 시스템 메시지: 평가자 가이드\n",
    "            {\"role\": \"user\", \"content\": user_prompt}  # 사용자 메시지: 질문과 응답들\n",
    "        ],\n",
    "        temperature=0  # 출력의 일관성을 위해 온도 설정\n",
    "    )\n",
    "    \n",
    "    # 생성된 평가 결과 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_fusion_retrieval(pdf_path, test_queries, reference_answers=None, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    결합 기반 검색(fusion retrieval)을 다른 검색 방식과 비교하여 평가합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일 경로\n",
    "        test_queries (List[str]): 테스트용 쿼리 목록\n",
    "        reference_answers (List[str], optional): 기준 응답 목록 (선택 사항)\n",
    "        k (int): 검색할 문서 개수\n",
    "        alpha (float): 결합 검색 시 벡터 점수에 부여할 가중치\n",
    "\n",
    "    Returns:\n",
    "        Dict: 쿼리별 평가 결과 및 전체 분석 결과\n",
    "    \"\"\"\n",
    "    print(\"=== 결합 기반 검색 평가 시작 ===\\n\")\n",
    "    \n",
    "    # 문서를 처리하여 텍스트 추출, 청크 생성, 벡터/BM25 인덱스 구축\n",
    "    chunks, vector_store, bm25_index = process_document(pdf_path)\n",
    "    \n",
    "    # 쿼리별 평가 결과를 저장할 리스트 초기화\n",
    "    results = []\n",
    "    \n",
    "    # 각 테스트 쿼리에 대해 반복 평가 수행\n",
    "    for i, query in enumerate(test_queries):\n",
    "        print(f\"\\n\\n=== 쿼리 평가 중: {i+1}/{len(test_queries)} ===\")\n",
    "        print(f\"질문: {query}\")\n",
    "        \n",
    "        # 기준 응답이 있는 경우 가져오기\n",
    "        reference = None\n",
    "        if reference_answers and i < len(reference_answers):\n",
    "            reference = reference_answers[i]\n",
    "        \n",
    "        # 현재 쿼리에 대해 검색 방식 비교 실행\n",
    "        comparison = compare_retrieval_methods(\n",
    "            query, \n",
    "            chunks, \n",
    "            vector_store, \n",
    "            bm25_index, \n",
    "            k=k, \n",
    "            alpha=alpha,\n",
    "            reference_answer=reference\n",
    "        )\n",
    "        \n",
    "        # 비교 결과를 리스트에 추가\n",
    "        results.append(comparison)\n",
    "        \n",
    "        # 각 검색 방식의 응답 출력\n",
    "        print(\"\\n=== 벡터 기반 응답 ===\")\n",
    "        print(comparison[\"vector_result\"][\"response\"])\n",
    "        \n",
    "        print(\"\\n=== BM25 기반 응답 ===\")\n",
    "        print(comparison[\"bm25_result\"][\"response\"])\n",
    "        \n",
    "        print(\"\\n=== 결합 기반 응답 ===\")\n",
    "        print(comparison[\"fusion_result\"][\"response\"])\n",
    "        \n",
    "        print(\"\\n=== 응답 비교 결과 ===\")\n",
    "        print(comparison[\"comparison\"])\n",
    "    \n",
    "    # 전체 쿼리에 대한 결합 검색 성능 분석 생성\n",
    "    overall_analysis = generate_overall_analysis(results)\n",
    "    \n",
    "    # 전체 결과 및 분석 반환\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"overall_analysis\": overall_analysis\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_overall_analysis(results):\n",
    "    \"\"\"\n",
    "    결합 기반 검색(fusion retrieval)에 대한 전체 분석을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        results (List[Dict]): 각 쿼리별 평가 결과 목록\n",
    "\n",
    "    Returns:\n",
    "        str: 전체 분석 결과\n",
    "    \"\"\"\n",
    "    # 평가 프로세스를 안내하는 시스템 프롬프트\n",
    "    system_prompt = \"\"\"당신은 정보 검색 시스템 평가 전문가입니다. \n",
    "    여러 테스트 쿼리를 기반으로 다음 세 가지 검색 방식을 비교한 전체 분석을 작성해 주세요:\n",
    "    1. 벡터 기반 검색 (의미 유사도 기반)\n",
    "    2. BM25 키워드 검색 (키워드 일치 기반)\n",
    "    3. 결합 기반 검색 (두 가지 방식의 결합)\n",
    "\n",
    "    다음 항목에 집중해 주세요:\n",
    "    1. 각각의 방식이 가장 효과적인 쿼리 유형\n",
    "    2. 각 방식의 전반적인 강점과 약점\n",
    "    3. 결합 검색이 어떻게 절충점을 조율하는지\n",
    "    4. 각 방식을 언제 사용하는 것이 적절한지에 대한 권장 사항\n",
    "    \"\"\"\n",
    "\n",
    "    # 각 쿼리별 평가 내용을 요약한 문자열 생성\n",
    "    evaluations_summary = \"\"\n",
    "    for i, result in enumerate(results):\n",
    "        evaluations_summary += f\"쿼리 {i+1}: {result['query']}\\n\"\n",
    "        evaluations_summary += f\"비교 요약: {result['comparison'][:200]}...\\n\\n\"\n",
    "\n",
    "    # 사용자 프롬프트: 쿼리별 평가 요약 포함\n",
    "    user_prompt = f\"\"\"{len(results)}개의 쿼리에 대해 다양한 검색 방식을 평가한 결과를 바탕으로, \n",
    "    벡터 기반, BM25 기반, 결합 기반 검색 방식을 전반적으로 비교 분석해 주세요:\n",
    "\n",
    "    {evaluations_summary}\n",
    "\n",
    "    특히 결합 검색이 어떤 상황에서 개별 방식보다 효과적인지, \n",
    "    그리고 각 방식의 사용 권장 조건을 포함한 종합적인 분석을 작성해 주세요.\n",
    "    \"\"\"\n",
    "\n",
    "    # LLaMA 모델을 사용하여 전체 분석 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # 생성된 분석 결과 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Fusion Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 결합 기반 검색 평가 시작 ===\n",
      "\n",
      "dataset/AI_Understanding.pdf에서 텍스트 추출 중...\n",
      "21개의 텍스트 청크가 생성되었습니다\n",
      "청크 임베딩 생성 중...\n",
      "21개의 항목이 벡터 저장소에 추가됨\n",
      "BM25 인덱스에 21개의 문서가 포함되었습니다\n",
      "\n",
      "\n",
      "=== 쿼리 평가 중: 1/1 ===\n",
      "질문: 자연어 처리에서 트랜스포머 모델의 주요 응용 분야는 무엇인가요?\n",
      "\n",
      "=== 쿼리에 대한 검색 방식 비교: 자연어 처리에서 트랜스포머 모델의 주요 응용 분야는 무엇인가요? ===\n",
      "\n",
      "\n",
      "[1] 벡터 기반 RAG 실행 중...\n",
      "\n",
      "[2] BM25 기반 RAG 실행 중...\n",
      "\n",
      "[3] 결합 기반 RAG 실행 중...\n",
      "쿼리에 대한 하이브리드 검색 수행 중: 자연어 처리에서 트랜스포머 모델의 주요 응용 분야는 무엇인가요?\n",
      "하이브리드 검색으로 5개의 문서를 반환함\n",
      "\n",
      "[4] 응답 비교 중...\n",
      "\n",
      "=== 벡터 기반 응답 ===\n",
      "제공된 문맥에서는 자연어 처리(NLP)와 관련된 트랜스포머 모델의 주요 응용 분야에 대한 구체적인 언급이 없습니다. 그러나 일반적으로 트랜스포머 모델은 기계 번역, 텍스트 요약, 감정 분석, 질문 응답 시스템 등 다양한 NLP 작업에 널리 사용됩니다. 이러한 정보는 문맥에 포함되어 있지 않으므로, 트랜스포머 모델의 응용 분야에 대한 구체적인 내용을 제공할 수는 없습니다.\n",
      "\n",
      "=== BM25 기반 응답 ===\n",
      "제공된 문맥에서는 자연어 처리(NLP)와 관련된 트랜스포머 모델의 주요 응용 분야에 대한 구체적인 정보가 포함되어 있지 않습니다. 그러나 일반적으로 트랜스포머 모델은 기계 번역, 텍스트 요약, 감정 분석, 질문 응답 시스템 등 다양한 NLP 작업에 널리 사용됩니다. 이러한 모델은 특히 문맥을 이해하고 긴 문장을 처리하는 데 강력한 성능을 발휘합니다. 추가적인 정보가 필요하다면 다른 자료를 참조하시기 바랍니다.\n",
      "\n",
      "=== 결합 기반 응답 ===\n",
      "제공된 문맥에는 자연어 처리(NLP)에서 트랜스포머 모델의 주요 응용 분야에 대한 정보가 포함되어 있지 않습니다. 따라서 트랜스포머 모델의 응용 분야에 대한 구체적인 내용을 제공할 수 없습니다. 일반적으로 트랜스포머 모델은 기계 번역, 텍스트 요약, 감정 분석, 질문 응답 시스템 등 다양한 NLP 작업에 널리 사용됩니다. 추가적인 정보가 필요하시면 말씀해 주세요!\n",
      "\n",
      "=== 응답 비교 결과 ===\n",
      "세 가지 검색 방식의 응답을 비교해 보겠습니다.\n",
      "\n",
      "### 1. 벡터 기반 응답\n",
      "- **관련성**: 벡터 기반 응답은 트랜스포머 모델의 주요 응용 분야에 대한 구체적인 언급이 없다고 명시하고 있습니다. 그러나 일반적인 응용 분야를 나열하고 있어 관련성은 어느 정도 있습니다.\n",
      "- **정확성**: 응답에서 언급된 기계 번역, 텍스트 요약, 감정 분석, 질문 응답 시스템 등은 사실에 기반한 정확한 정보입니다.\n",
      "- **포괄성**: 응용 분야를 나열했지만, 문맥에 대한 구체적인 정보가 없다는 점에서 포괄성이 떨어집니다.\n",
      "- **명확성 및 일관성**: 응답은 명확하고 일관되지만, 문맥에 대한 언급이 부족하여 다소 제한적입니다.\n",
      "\n",
      "### 2. BM25 키워드 기반 응답\n",
      "- **관련성**: BM25 응답도 트랜스포머 모델의 응용 분야에 대한 구체적인 정보가 없다고 언급하며, 일반적인 응용 분야를 나열합니다. 이로 인해 관련성은 높습니다.\n",
      "- **정확성**: 기계 번역, 텍스트 요약, 감정 분석, 질문 응답 시스템 등은 정확한 정보입니다. 추가적으로 문맥을 이해하고 긴 문장을 처리하는 데 강력한 성능을 발휘한다고 언급한 점은 유용합니다.\n",
      "- **포괄성**: 응용 분야를 나열하고, 트랜스포머 모델의 성능에 대한 추가 정보를 제공하여 포괄성이 높습니다.\n",
      "- **명확성 및 일관성**: 응답은 명확하고 일관되며, 추가적인 정보가 필요하다는 제안도 포함되어 있어 독자에게 친절합니다.\n",
      "\n",
      "### 3. 결합 기반 응답\n",
      "- **관련성**: 결합 기반 응답은 벡터 기반과 BM25의 중간 정도의 관련성을 보입니다. 문맥에 대한 언급이 없다고 하면서도 일반적인 응용 분야를 나열합니다.\n",
      "- **정확성**: 기계 번역, 텍스트 요약, 감정 분석, 질문 응답 시스템 등은 정확한 정보입니다.\n",
      "- **포괄성**: 응용 분야를 나열했지만, 문맥에 대한 구체적인 정보가 없다는 점에서 포괄성이 떨어집니다.\n",
      "- **명확성 및 일관성**: 응답은 명확하고 일관되지만, 추가적인 정보 요청이 포함되어 있어 독자에게 친절한 점은 긍정적입니다.\n",
      "\n",
      "### 결론\n",
      "가장 잘 대응한 방식은 **BM25 키워드 기반 응답**입니다. 그 이유는 다음과 같습니다:\n",
      "- BM25 응답은 관련성과 정확성 모두에서 높은 점수를 받았으며, 트랜스포머 모델의 성능에 대한 추가적인 정보를 제공하여 포괄성을 높였습니다.\n",
      "- 명확하고 일관된 표현으로 독자에게 친절한 접근을 하였고, 추가적인 정보 요청을 통해 대화의 연속성을 유지했습니다.\n",
      "\n",
      "### 각 응답 방식의 장점과 단점\n",
      "- **벡터 기반 검색**\n",
      "  - 장점: 의미적 유사성을 기반으로 하여 더 깊이 있는 정보 검색 가능.\n",
      "  - 단점: 문맥에 대한 구체적인 정보가 부족할 수 있음.\n",
      "\n",
      "- **BM25 키워드 기반 검색**\n",
      "  - 장점: 키워드 일치로 인해 정확하고 관련성 높은 정보를 제공.\n",
      "  - 단점: 문맥을 고려하지 못할 경우 정보의 깊이가 떨어질 수 있음.\n",
      "\n",
      "- **결합 기반 검색**\n",
      "  - 장점: 두 가지 방법의 장점을 결합하여 더 나은 결과를 도출할 수 있음.\n",
      "  - 단점: 특정 상황에서 두 방법의 단점이 결합될 수 있어 최적의 결과를 보장하지 않을 수 있음.\n",
      "\n",
      "\n",
      "***전체 평가 요약***\n",
      "\n",
      "### 검색 방식 비교 분석\n",
      "\n",
      "#### 1. 벡터 기반 검색 (의미 유사도 기반)\n",
      "- **가장 효과적인 쿼리 유형**: 자연어 쿼리, 의미가 중요한 질문, 또는 동의어와 유사한 표현이 포함된 쿼리에서 효과적입니다. 예를 들어, \"자연어 처리에서 트랜스포머 모델의 주요 응용 분야는 무엇인가요?\"와 같은 질문은 벡터 기반 검색의 강점을 잘 활용할 수 있습니다.\n",
      "- **강점**: \n",
      "  - 의미적 유사성을 기반으로 하여, 동의어나 유사한 표현을 포함한 문서도 검색할 수 있습니다.\n",
      "  - 문맥을 이해하고, 다양한 표현을 포괄적으로 처리할 수 있습니다.\n",
      "- **약점**: \n",
      "  - 특정 키워드가 명확하게 포함되지 않은 경우, 관련성이 낮은 결과가 나올 수 있습니다.\n",
      "  - 대량의 데이터에서 벡터화 과정이 복잡하고 시간이 소요될 수 있습니다.\n",
      "\n",
      "#### 2. BM25 키워드 검색 (키워드 일치 기반)\n",
      "- **가장 효과적인 쿼리 유형**: 특정 키워드가 명확하게 포함된 쿼리, 또는 정보 검색에서 정확한 일치를 요구하는 경우에 효과적입니다. 예를 들어, \"트랜스포머 모델\"과 같은 특정 용어가 포함된 쿼리에서 강력한 성능을 발휘합니다.\n",
      "- **강점**: \n",
      "  - 키워드 일치 기반으로, 명확한 정보 검색에 강력한 성능을 보입니다.\n",
      "  - 문서의 중요도를 평가하는 데 효과적이며, 검색 결과의 순위를 잘 조정할 수 있습니다.\n",
      "- **약점**: \n",
      "  - 동의어나 유사한 표현을 인식하지 못해, 관련성이 떨어질 수 있습니다.\n",
      "  - 사용자가 입력한 쿼리와 문서 간의 키워드 일치가 부족할 경우, 유용한 정보를 놓칠 수 있습니다.\n",
      "\n",
      "#### 3. 결합 기반 검색 (두 가지 방식의 결합)\n",
      "- **가장 효과적인 쿼리 유형**: 다양한 표현과 의미를 포함하는 복잡한 쿼리에서 효과적입니다. 예를 들어, \"자연어 처리에서 트랜스포머 모델의 주요 응용 분야는 무엇인가요?\"와 같은 질문은 결합 검색의 장점을 잘 활용할 수 있습니다.\n",
      "- **강점**: \n",
      "  - 벡터 기반 검색의 의미적 유사성과 BM25의 키워드 일치의 장점을 결합하여, 보다 포괄적이고 정확한 검색 결과를 제공합니다.\n",
      "  - 사용자의 다양한 쿼리 스타일에 유연하게 대응할 수 있습니다.\n",
      "- **약점**: \n",
      "  - 두 가지 방식의 조합이 항상 최적의 결과를 보장하지는 않으며, 조정이 필요할 수 있습니다.\n",
      "  - 시스템의 복잡성이 증가하여, 구현 및 유지 관리가 어려울 수 있습니다.\n",
      "\n",
      "### 결합 검색의 절충점 조율\n",
      "결합 검색은 벡터 기반 검색의 의미적 유사성과 BM25의 키워드 일치의 장점을 통합하여, 사용자가 입력한 쿼리의 다양한 표현을 포괄적으로 처리할 수 있습니다. 예를 들어, 사용자가 \"트랜스포머 모델\"이라는 특정 키워드를 입력하더라도, 벡터 기반 검색을 통해 관련된 동의어나 유사한 표현을 포함한 문서도 함께 검색할 수 있습니다. 이는 사용자가 원하는 정보를 보다 정확하게 찾을 수 있도록 도와줍니다.\n",
      "\n",
      "### 사용 권장 조건\n",
      "- **벡터 기반 검색**: 자연어 쿼리, 의미가 중요한 질문, 동의어가 포함된 쿼리에서 사용.\n",
      "- **BM25 키워드 검색**: 특정 키워드가 명확하게 포함된 쿼리, 정보 검색에서 정확한 일치를 요구하는 경우에 사용.\n",
      "- **결합 기반 검색**: 다양한 표현과 의미를 포함하는 복잡한 쿼리, 또는 사용자의 쿼리 스타일이 다양할 때 사용.\n",
      "\n",
      "결론적으로, 각 검색 방식은 특정 상황에서 강점을 발휘하며, 결합 검색은 이러한 강점을 조화롭게 통합하여 보다 효과적인 정보 검색을 가능하게 합니다.\n"
     ]
    }
   ],
   "source": [
    "# PDF 문서 경로\n",
    "# 지식 검색 테스트를 위한 AI 정보가 포함된 PDF 문서 경로\n",
    "pdf_path = \"dataset/AI_Understanding.pdf\"\n",
    "\n",
    "# 하나의 AI 관련 테스트 쿼리 정의\n",
    "test_queries = [\n",
    "    \"자연어 처리에서 트랜스포머 모델의 주요 응용 분야는 무엇인가요?\"  # AI 관련 쿼리\n",
    "]\n",
    "\n",
    "# (선택 사항) 기준이 되는 정답\n",
    "reference_answers = [\n",
    "    \"트랜스포머 모델은 기계 번역, 텍스트 요약, 질문 답변, 감정 분석, 텍스트 생성 등의 애플리케이션을 통해 자연어 처리에 혁명을 일으켰습니다. 텍스트의 장거리 종속성을 포착하는 데 탁월하며 BERT, GPT, T5와 같은 모델의 기반이 되었습니다.\",\n",
    "]\n",
    "# 검색 설정값 정의\n",
    "k = 5  # 검색할 문서 개수\n",
    "alpha = 0.5  # 벡터 점수 가중치 (0.5이면 벡터와 BM25 동일 비중)\n",
    "\n",
    "# 평가 실행\n",
    "evaluation_results = evaluate_fusion_retrieval(\n",
    "    pdf_path=pdf_path,\n",
    "    test_queries=test_queries,\n",
    "    reference_answers=reference_answers,\n",
    "    k=k,\n",
    "    alpha=alpha\n",
    ")\n",
    "\n",
    "# 전체 분석 결과 출력\n",
    "print(\"\\n\\n***전체 평가 요약***\\n\")\n",
    "print(evaluation_results[\"overall_analysis\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

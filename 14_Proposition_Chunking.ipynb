{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Proposition Chunking for Enhanced RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import fitz\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Text from a PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트를 추출합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일 경로\n",
    "\n",
    "    Returns:\n",
    "        str: PDF에서 추출된 전체 텍스트\n",
    "    \"\"\"\n",
    "    # PDF 파일 열기\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # 전체 텍스트를 저장할 문자열 초기화\n",
    "\n",
    "    # 각 페이지를 순회하며 텍스트 추출\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]               # 해당 페이지 가져오기\n",
    "        text = page.get_text(\"text\")         # 텍스트 형식으로 내용 추출\n",
    "        all_text += text                     # 추출된 텍스트 누적\n",
    "\n",
    "    # 추출된 전체 텍스트 반환\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking the Extracted Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=800, overlap=100):\n",
    "    \"\"\"\n",
    "    텍스트를 일정 길이로 겹치게 분할합니다.\n",
    "\n",
    "    Args:\n",
    "        text (str): 분할할 원본 텍스트\n",
    "        chunk_size (int): 각 청크의 문자 수 (기본: 800자)\n",
    "        overlap (int): 청크 간 중첩 길이 (기본: 100자)\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: 텍스트와 메타데이터를 포함한 청크 딕셔너리 리스트\n",
    "    \"\"\"\n",
    "    chunks = []  # 청크들을 저장할 빈 리스트 초기화\n",
    "\n",
    "    # 지정된 청크 크기와 중첩 길이에 따라 텍스트 분할\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunk = text[i:i + chunk_size]  # 해당 범위만큼 청크 추출\n",
    "        if chunk:  # 빈 청크는 제외\n",
    "            chunks.append({\n",
    "                \"text\": chunk,  # 청크 본문\n",
    "                \"chunk_id\": len(chunks) + 1,  # 청크 고유 ID\n",
    "                \"start_char\": i,  # 청크 시작 인덱스\n",
    "                \"end_char\": i + len(chunk)  # 청크 끝 인덱스\n",
    "            })\n",
    "\n",
    "    # 생성된 청크 수 출력\n",
    "    print(f\"Total {len(chunks)}개의 텍스트 청크가 생성되었습니다.\")\n",
    "    return chunks  # 청크 리스트 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Vector Store Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    NumPy를 사용한 간단한 벡터 저장소 구현입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        벡터 저장소를 초기화합니다.\n",
    "        \"\"\"\n",
    "        self.vectors = []  # 임베딩 벡터를 저장할 리스트\n",
    "        self.texts = []  # 원본 텍스트를 저장할 리스트\n",
    "        self.metadata = []  # 각 텍스트의 메타데이터를 저장할 리스트\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        항목을 벡터 저장소에 추가합니다.\n",
    "\n",
    "        Args:\n",
    "        text (str): 원본 텍스트\n",
    "        embedding (List[float]): 임베딩 벡터\n",
    "        metadata (dict, 선택): 추가적인 메타데이터\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))  # 임베딩을 넘파이 배열로 변환하여 vectors 리스트에 추가\n",
    "        self.texts.append(text)  # 원본 텍스트를 texts 리스트에 추가\n",
    "        self.metadata.append(metadata or {})  # 메타데이터를 metadata 리스트에 추가, 없으면 빈 딕셔너리 사용\n",
    "    \n",
    "    def similarity_search(self, query_embedding, k=5, filter_func=None):\n",
    "        \"\"\"\n",
    "        쿼리 임베딩과 가장 유사한 항목들을 찾습니다.\n",
    "\n",
    "        Args:\n",
    "        query_embedding (List[float]): 쿼리 임베딩 벡터\n",
    "        k (int): 반환할 결과 수\n",
    "        filter_func (callable, 선택): 결과를 필터링할 함수\n",
    "\n",
    "        Returns:\n",
    "        List[Dict]: 텍스트와 메타데이터, 유사도 점수를 포함한 상위 k개 유사 항목 리스트\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []  # 저장된 벡터가 없다면 빈 리스트 반환\n",
    "        \n",
    "        # 쿼리 임베딩을 넘파이 배열로 변환\n",
    "        query_vector = np.array(query_embedding)\n",
    "        \n",
    "        # 코사인 유사도를 사용하여 유사도 계산\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            # 필터 함수가 있다면 해당 메타데이터를 기준으로 필터링\n",
    "            if filter_func and not filter_func(self.metadata[i]):\n",
    "                continue\n",
    "                \n",
    "            # 코사인 유사도 계산\n",
    "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i, similarity))  # 인덱스와 유사도 점수를 추가\n",
    "        \n",
    "        # 유사도를 기준으로 내림차순 정렬\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 상위 k개의 결과 반환\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],  # 텍스트 추가\n",
    "                \"metadata\": self.metadata[idx],  # 메타데이터 추가\n",
    "                \"similarity\": score  # 유사도 점수 추가\n",
    "            })\n",
    "        \n",
    "        return results  # 상위 k개 결과 리스트 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    주어진 텍스트에 대해 임베딩을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        text (str 또는 List[str]): 임베딩을 생성할 입력 텍스트(또는 텍스트 리스트)\n",
    "        model (str): 사용할 임베딩 모델 이름\n",
    "\n",
    "    Returns:\n",
    "        List[float] 또는 List[List[float]]: 생성된 임베딩 벡터 또는 벡터 리스트\n",
    "    \"\"\"\n",
    "    # 입력이 문자열 하나일 수도 있고, 문자열 리스트일 수도 있으므로 리스트 형태로 통일\n",
    "    input_text = text if isinstance(text, list) else [text]\n",
    "\n",
    "    # 지정된 모델을 사용하여 임베딩 생성 요청\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=input_text\n",
    "    )\n",
    "\n",
    "    # 입력이 단일 문자열이었을 경우, 첫 번째 임베딩만 반환\n",
    "    if isinstance(text, str):\n",
    "        return response.data[0].embedding\n",
    "\n",
    "    # 여러 문자열일 경우, 모든 임베딩 리스트 반환\n",
    "    return [item.embedding for item in response.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposition Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_propositions(chunk):\n",
    "    \"\"\"\n",
    "    텍스트 청크에서 원자적이고 자족적인 명제들을 생성합니다.\n",
    "\n",
    "    매개변수:\n",
    "        chunk (Dict): 텍스트와 메타데이터를 포함한 청크\n",
    "\n",
    "    반환값:\n",
    "        List[str]: 생성된 명제 리스트\n",
    "    \"\"\"\n",
    "    # 명제 생성을 위한 시스템 프롬프트 정의\n",
    "    system_prompt = \"\"\"다음 텍스트를 단순하고 자족적인 명제들로 분해해 주세요.\n",
    "    각 명제는 다음 기준을 충족해야 합니다:\n",
    "\n",
    "    1. 하나의 사실만 표현할 것: 각 명제는 하나의 구체적인 사실이나 주장만을 담아야 합니다.\n",
    "    2. 문맥 없이 이해 가능할 것: 명제는 자족적이어야 하며, 추가적인 문맥 없이도 이해되어야 합니다.\n",
    "    3. 대명사 대신 전체 이름 사용할 것: 대명사나 모호한 지시어 대신, 전체 엔터티 이름을 사용하세요.\n",
    "    4. 관련 날짜/수식어 포함: 필요한 경우 명확성을 위해 날짜, 시간, 수식어를 포함하세요.\n",
    "    5. 하나의 주어-술어 관계만 포함: 연결사 없이 하나의 주어와 그에 해당하는 동작 또는 속성만 표현하세요.\n",
    "\n",
    "    명제 리스트만 출력하고, 그 외의 설명이나 추가 텍스트는 포함하지 마세요.\"\"\"\n",
    "\n",
    "\n",
    "    # 사용자 프롬프트: 명제로 변환할 텍스트 청크\n",
    "    user_prompt = f\"명제(proposition)로 변환할 텍스트:\\n\\n{chunk['text']}\"\n",
    "    \n",
    "    # 모델 호출\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0  # 창의성보다 정확성을 중시\n",
    "    )\n",
    "    \n",
    "    # 응답으로부터 명제 줄 단위 추출\n",
    "    raw_propositions = response.choices[0].message.content.strip().split('\\n')\n",
    "    \n",
    "    # 불필요한 번호, 기호 등 제거하여 명제 정리\n",
    "    clean_propositions = []\n",
    "    for prop in raw_propositions:\n",
    "        cleaned = re.sub(r'^\\s*(\\d+\\.|\\-|\\*)\\s*', '', prop).strip()\n",
    "        if cleaned and len(cleaned) > 10:  # 너무 짧거나 빈 명제는 제외\n",
    "            clean_propositions.append(cleaned)\n",
    "    \n",
    "    return clean_propositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Checking for Propositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_proposition(proposition, original_text):\n",
    "    \"\"\"\n",
    "    Evaluate a proposition's quality based on accuracy, clarity, completeness, and conciseness.\n",
    "    \n",
    "    Args:\n",
    "        proposition (str): The proposition to evaluate\n",
    "        original_text (str): The original text for comparison\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Scores for each evaluation dimension\n",
    "    \"\"\"\n",
    "    # System prompt to instruct the AI on how to evaluate the proposition\n",
    "    system_prompt = \"\"\"You are an expert at evaluating the quality of propositions extracted from text.\n",
    "    Rate the given proposition on the following criteria (scale 1-10):\n",
    "\n",
    "    - Accuracy: How well the proposition reflects information in the original text\n",
    "    - Clarity: How easy it is to understand the proposition without additional context\n",
    "    - Completeness: Whether the proposition includes necessary details (dates, qualifiers, etc.)\n",
    "    - Conciseness: Whether the proposition is concise without losing important information\n",
    "\n",
    "    The response must be in valid JSON format with numerical scores for each criterion:\n",
    "    {\"accuracy\": X, \"clarity\": X, \"completeness\": X, \"conciseness\": X}\n",
    "    \"\"\"\n",
    "\n",
    "    # User prompt containing the proposition and the original text\n",
    "    user_prompt = f\"\"\"Proposition: {proposition}\n",
    "\n",
    "    Original Text: {original_text}\n",
    "\n",
    "    Please provide your evaluation scores in JSON format.\"\"\"\n",
    "\n",
    "    # Generate response from the model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    try:\n",
    "        scores = json.loads(response.choices[0].message.content.strip())\n",
    "        return scores\n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback if JSON parsing fails\n",
    "        return {\n",
    "            \"accuracy\": 5,\n",
    "            \"clarity\": 5,\n",
    "            \"completeness\": 5,\n",
    "            \"conciseness\": 5\n",
    "        }\n",
    "    \n",
    "    \n",
    "import json\n",
    "\n",
    "def evaluate_proposition(proposition, original_text):\n",
    "    \"\"\"\n",
    "    명제를 정확성, 명확성, 완전성, 간결성 기준으로 평가합니다.\n",
    "\n",
    "    Args:\n",
    "        proposition (str): 평가할 명제\n",
    "        original_text (str): 명제가 추출된 원본 텍스트\n",
    "\n",
    "    Returns:\n",
    "        Dict: 각 평가 기준에 대한 점수 (1~10)\n",
    "    \"\"\"\n",
    "    # 평가 기준을 설명하는 시스템 프롬프트\n",
    "    system_prompt = \"\"\"귀하는 텍스트에서 추출한 명제의 품질을 평가하는 전문가입니다.\n",
    "    다음 기준에 따라 주어진 명제를 평가하세요(1~10점 척도):\n",
    "\n",
    "    - Accuracy: 명제가 원문 텍스트의 정보를 얼마나 잘 반영하는지 여부\n",
    "    - Clarity: 추가적인 맥락 없이도 명제를 얼마나 쉽게 이해할 수 있는지 여부\n",
    "    - Completeness: 명제에 필요한 세부 사항(날짜, 한정어 등)이 포함되어 있는지 여부\n",
    "    - Conciseness: 명제가 중요한 정보를 놓치지 않고 간결한지 여부\n",
    "\n",
    "    응답은 각 기준에 대한 수치 점수가 포함된 유효한 JSON 형식이어야 합니다:\n",
    "        {\"accuracy\": X, \"clarity\": X, \"completeness\": X, \"conciseness\": X}\n",
    "        \"\"\"\n",
    "\n",
    "    # 사용자 입력: 명제와 원문\n",
    "    user_prompt = f\"\"\"Proposition: {proposition}\n",
    "\n",
    "    Original Text: {original_text}\n",
    "\n",
    "    평가 점수를 JSON 형식으로 제공해 주세요.\"\"\"\n",
    "\n",
    "    # LLM을 호출하여 평가 점수 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},  # JSON 형식 응답 요청\n",
    "        temperature=0  # 일관된 평가를 위해 창의성 최소화\n",
    "    )\n",
    "    \n",
    "    # 모델 응답에서 JSON 파싱 시도\n",
    "    try:\n",
    "        scores = json.loads(response.choices[0].message.content.strip())\n",
    "        return scores\n",
    "    except json.JSONDecodeError:\n",
    "        # JSON 파싱 실패 시, 기본 점수 반환\n",
    "        return {\n",
    "            \"accuracy\": 5,\n",
    "            \"clarity\": 5,\n",
    "            \"completeness\": 5,\n",
    "            \"conciseness\": 5\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Proposition Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_document_into_propositions(pdf_path, chunk_size=800, chunk_overlap=100, \n",
    "                                      quality_thresholds=None):\n",
    "    \"\"\"\n",
    "    문서를 처리하여 품질 기준을 통과한 명제들을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일 경로\n",
    "        chunk_size (int): 각 청크의 문자 수\n",
    "        chunk_overlap (int): 청크 간 중첩 문자 수\n",
    "        quality_thresholds (Dict): 명제 품질 평가 기준 점수\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Dict], List[Dict]]: 원본 청크 리스트, 품질 필터링된 명제 리스트\n",
    "    \"\"\"\n",
    "    # 품질 기준이 없을 경우 기본 기준 설정\n",
    "    if quality_thresholds is None:\n",
    "        quality_thresholds = {\n",
    "            \"accuracy\": 7,\n",
    "            \"clarity\": 7,\n",
    "            \"completeness\": 7,\n",
    "            \"conciseness\": 7\n",
    "        }\n",
    "    \n",
    "    # PDF에서 텍스트 추출\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # 추출된 텍스트를 청크 단위로 분할\n",
    "    chunks = chunk_text(text, chunk_size, chunk_overlap)\n",
    "    \n",
    "    all_propositions = []  # 전체 명제 저장 리스트 초기화\n",
    "\n",
    "    print(\"청크로부터 명제를 생성 중...\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"{i+1}/{len(chunks)} 번째 청크 처리 중...\")\n",
    "\n",
    "        # 현재 청크에 대해 명제 생성\n",
    "        chunk_propositions = generate_propositions(chunk)\n",
    "        print(f\"생성된 명제 수: {len(chunk_propositions)}\")\n",
    "\n",
    "        # 각 명제를 메타데이터와 함께 저장\n",
    "        for prop in chunk_propositions:\n",
    "            proposition_data = {\n",
    "                \"text\": prop,\n",
    "                \"source_chunk_id\": chunk[\"chunk_id\"],\n",
    "                \"source_text\": chunk[\"text\"]\n",
    "            }\n",
    "            all_propositions.append(proposition_data)\n",
    "\n",
    "    # 명제 품질 평가 단계\n",
    "    print(\"\\n명제 품질 평가 중...\")\n",
    "    quality_propositions = []  # 품질 기준을 통과한 명제 리스트\n",
    "\n",
    "    for i, prop in enumerate(all_propositions):\n",
    "        if i % 10 == 0:  # 10개마다 진행 상황 출력\n",
    "            print(f\"{i+1}/{len(all_propositions)} 번째 명제 평가 중...\")\n",
    "\n",
    "        # 해당 명제의 품질 점수 평가\n",
    "        scores = evaluate_proposition(prop[\"text\"], prop[\"source_text\"])\n",
    "        prop[\"quality_scores\"] = scores\n",
    "\n",
    "        # 모든 기준 점수를 통과하는지 확인\n",
    "        passes_quality = True\n",
    "        for metric, threshold in quality_thresholds.items():\n",
    "            if scores.get(metric, 0) < threshold:\n",
    "                passes_quality = False\n",
    "                break\n",
    "\n",
    "        if passes_quality:\n",
    "            quality_propositions.append(prop)\n",
    "        else:\n",
    "            print(f\"품질 기준 미달 명제: {prop['text'][:50]}...\")\n",
    "\n",
    "    print(f\"\\n최종 통과 명제 수: {len(quality_propositions)}/{len(all_propositions)}\")\n",
    "\n",
    "    # 결과 반환: 전체 청크와, 품질 기준 통과 명제\n",
    "    return chunks, quality_propositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Vector Stores for Both Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vector_stores(chunks, propositions):\n",
    "    \"\"\"\n",
    "    문서 청크와 명제 기반의 벡터 저장소를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        chunks (List[Dict]): 원본 문서 청크 리스트\n",
    "        propositions (List[Dict]): 품질 필터링된 명제 리스트\n",
    "\n",
    "    Returns:\n",
    "        Tuple[SimpleVectorStore, SimpleVectorStore]: 청크 기반, 명제 기반 벡터 저장소\n",
    "    \"\"\"\n",
    "    # 청크 기반 벡터 저장소 생성\n",
    "    chunk_store = SimpleVectorStore()\n",
    "    \n",
    "    # 청크 텍스트 추출 및 임베딩 생성\n",
    "    chunk_texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    print(f\"{len(chunk_texts)}개의 청크에 대해 임베딩 생성 중...\")\n",
    "    chunk_embeddings = create_embeddings(chunk_texts)\n",
    "    \n",
    "    # 메타데이터 생성 후 벡터 저장소에 추가\n",
    "    chunk_metadata = [{\"chunk_id\": chunk[\"chunk_id\"], \"type\": \"chunk\"} for chunk in chunks]\n",
    "    chunk_store.add_items(chunk_texts, chunk_embeddings, chunk_metadata)\n",
    "    \n",
    "    # 명제 기반 벡터 저장소 생성\n",
    "    prop_store = SimpleVectorStore()\n",
    "    \n",
    "    # 명제 텍스트 추출 및 임베딩 생성\n",
    "    prop_texts = [prop[\"text\"] for prop in propositions]\n",
    "    print(f\"{len(prop_texts)}개의 명제에 대해 임베딩 생성 중...\")\n",
    "    prop_embeddings = create_embeddings(prop_texts)\n",
    "    \n",
    "    # 명제 메타데이터 생성 후 저장소에 추가\n",
    "    prop_metadata = [\n",
    "        {\n",
    "            \"type\": \"proposition\", \n",
    "            \"source_chunk_id\": prop[\"source_chunk_id\"],\n",
    "            \"quality_scores\": prop[\"quality_scores\"]\n",
    "        } \n",
    "        for prop in propositions\n",
    "    ]\n",
    "    prop_store.add_items(prop_texts, prop_embeddings, prop_metadata)\n",
    "    \n",
    "    # 두 개의 저장소 반환\n",
    "    return chunk_store, prop_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query and Retrieval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_store(query, vector_store, k=5):\n",
    "    \"\"\"\n",
    "    쿼리를 기반으로 벡터 저장소에서 관련 항목들을 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str): 사용자 쿼리\n",
    "        vector_store (SimpleVectorStore): 검색 대상 벡터 저장소\n",
    "        k (int): 반환할 결과 수 (기본값: 5개)\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: 유사도 점수와 메타데이터가 포함된 검색 결과 리스트\n",
    "    \"\"\"\n",
    "    # 쿼리를 임베딩으로 변환\n",
    "    query_embedding = create_embeddings(query)\n",
    "\n",
    "    # 벡터 저장소에서 상위 k개 유사 항목 검색\n",
    "    results = vector_store.similarity_search(query_embedding, k=k)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_retrieval_approaches(query, chunk_store, prop_store, k=5):\n",
    "    \"\"\"\n",
    "    하나의 쿼리에 대해 청크 기반과 명제 기반 검색 방식을 비교합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str): 사용자 검색 쿼리\n",
    "        chunk_store (SimpleVectorStore): 청크 기반 벡터 저장소\n",
    "        prop_store (SimpleVectorStore): 명제 기반 벡터 저장소\n",
    "        k (int): 각 저장소에서 검색할 결과 수\n",
    "\n",
    "    Returns:\n",
    "        Dict: 두 검색 방식의 결과를 포함한 비교 정보\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== 쿼리: {query} ===\")\n",
    "    \n",
    "    # 명제 기반 검색\n",
    "    print(\"\\n[명제 기반 검색 수행 중...]\")\n",
    "    prop_results = retrieve_from_store(query, prop_store, k)\n",
    "    \n",
    "    # 청크 기반 검색\n",
    "    print(\"[청크 기반 검색 수행 중...]\")\n",
    "    chunk_results = retrieve_from_store(query, chunk_store, k)\n",
    "    \n",
    "    # 명제 기반 결과 출력\n",
    "    print(\"\\n=== 명제 기반 결과 ===\")\n",
    "    for i, result in enumerate(prop_results):\n",
    "        print(f\"{i+1}) {result['text']} (유사도: {result['similarity']:.4f})\")\n",
    "    \n",
    "    # 청크 기반 결과 출력\n",
    "    print(\"\\n=== 청크 기반 결과 ===\")\n",
    "    for i, result in enumerate(chunk_results):\n",
    "        # 너무 긴 텍스트는 150자까지만 출력\n",
    "        truncated_text = result['text'][:150] + \"...\" if len(result['text']) > 150 else result['text']\n",
    "        print(f\"{i+1}) {truncated_text} (유사도: {result['similarity']:.4f})\")\n",
    "    \n",
    "    # 결과 딕셔너리로 반환\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"proposition_results\": prop_results,\n",
    "        \"chunk_results\": chunk_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Generation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, results, result_type=\"proposition\"):\n",
    "    \"\"\"\n",
    "    검색된 결과를 기반으로 AI 응답을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str): 사용자 질문\n",
    "        results (List[Dict]): 검색된 항목 리스트\n",
    "        result_type (str): 검색 결과의 유형 ('proposition' 또는 'chunk')\n",
    "\n",
    "    Returns:\n",
    "        str: 생성된 AI 응답\n",
    "    \"\"\"\n",
    "    # 검색된 텍스트들을 하나의 문맥(context) 문자열로 결합\n",
    "    context = \"\\n\\n\".join([result[\"text\"] for result in results])\n",
    "    \n",
    "    # AI에게 응답 지침을 주는 시스템 프롬프트 정의\n",
    "    system_prompt = f\"\"\"당신은 검색된 정보를 바탕으로 질문에 답하는 AI 어시스턴트입니다.\n",
    "    당신의 답변은 지식 기반에서 검색된 다음의 {result_type}들을 기반으로 해야 합니다.\n",
    "    검색된 정보만으로 질문에 답할 수 없다면, 그 한계를 명확히 인정해야 합니다.\"\"\"\n",
    "\n",
    "    # 사용자 프롬프트: 질문 + 검색된 문맥\n",
    "    user_prompt = f\"\"\"Query: {query}\n",
    "\n",
    "    Retrieved {result_type}s:\n",
    "    {context}\n",
    "\n",
    "    검색된 정보를 바탕으로 쿼리에 답변해 주세요.\"\"\"\n",
    "\n",
    "    # OpenAI 또는 호환 클라이언트를 통해 응답 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2  # 비교적 낮은 창의성 (정보 충실도 중시)\n",
    "    )\n",
    "    \n",
    "    # 응답 텍스트만 반환\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_responses(query, prop_response, chunk_response, reference_answer=None):\n",
    "    \"\"\"\n",
    "    명제 기반 응답과 청크 기반 응답을 비교 평가합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str): 사용자 질문\n",
    "        prop_response (str): 명제 기반 검색으로 생성된 응답\n",
    "        chunk_response (str): 청크 기반 검색으로 생성된 응답\n",
    "        reference_answer (str, 선택): 비교용 정답 (있을 경우 정확성 기준 제공)\n",
    "\n",
    "    Returns:\n",
    "        str: 평가 분석 결과 (자연어 텍스트)\n",
    "    \"\"\"\n",
    "    # 평가 시스템 프롬프트 정의: 평가 기준과 방식 설명\n",
    "    system_prompt = \"\"\"당신은 정보 검색 시스템 평가 전문가입니다.\n",
    "    하나의 쿼리에 대해 생성된 두 개의 응답을 비교하세요. \n",
    "    하나는 명제 기반 검색(proposition-based retrieval), 다른 하나는 청크 기반 검색(chunk-based retrieval)에 의해 생성된 응답입니다.\n",
    "\n",
    "    다음 기준에 따라 두 응답을 평가하십시오:\n",
    "    1. 정확성(Accuracy): 어느 응답이 사실적으로 더 정확한 정보를 제공하는가?\n",
    "    2. 관련성(Relevance): 어느 응답이 쿼리의 의도에 더 잘 부합하는가?\n",
    "    3. 간결성(Conciseness): 어느 응답이 핵심을 놓치지 않으면서 더 간결하게 설명하는가?\n",
    "    4. 명확성(Clarity): 어느 응답이 더 이해하기 쉬운가?\n",
    "\n",
    "    각 방식의 강점과 약점을 구체적으로 서술하십시오.\"\"\"\n",
    "\n",
    "\n",
    "    # 사용자 프롬프트 구성: 쿼리 및 두 응답 포함\n",
    "    user_prompt = f\"\"\"Query: {query}\n",
    "\n",
    "    Response from Proposition-Based Retrieval:\n",
    "    {prop_response}\n",
    "\n",
    "    Response from Chunk-Based Retrieval:\n",
    "    {chunk_response}\"\"\"\n",
    "\n",
    "    # 참조 정답이 제공된 경우, 프롬프트에 포함하여 사실성 비교 가능하도록 함\n",
    "    if reference_answer:\n",
    "        user_prompt += f\"\"\"\n",
    "\n",
    "    Reference Answer (for factual checking):\n",
    "    {reference_answer}\"\"\"\n",
    "\n",
    "    # 사용자에게 비교 평가 요청\n",
    "    user_prompt += \"\"\"\n",
    "    이 두 가지 응답을 자세히 비교하여 어떤 접근 방식이 더 나은 성과를 냈는지, 그 이유는 무엇인지 설명해 주세요.\"\"\"\n",
    "\n",
    "    # 평가 분석 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0  # 일관된 평가를 위해 창의성 최소화\n",
    "    )\n",
    "    \n",
    "    # 평가 결과 텍스트 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete End-to-End Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_proposition_chunking_evaluation(pdf_path, test_queries, reference_answers=None):\n",
    "    \"\"\"\n",
    "    명제 기반 청크화 vs 일반 청크화에 대한 종합 평가를 실행합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일 경로\n",
    "        test_queries (List[str]): 테스트할 질문 리스트\n",
    "        reference_answers (List[str], 선택): 정답 리스트 (있을 경우 정확성 평가에 사용)\n",
    "\n",
    "    Returns:\n",
    "        Dict: 평가 결과, 전체 분석, 명제/청크 개수 포함\n",
    "    \"\"\"\n",
    "    print(\"***명제 기반 청크화 평가 시작***\\n\")\n",
    "    \n",
    "    # 문서 처리 → 청크 및 명제 생성\n",
    "    chunks, propositions = process_document_into_propositions(pdf_path)\n",
    "    \n",
    "    # 벡터 저장소 구축 (청크용, 명제용)\n",
    "    chunk_store, prop_store = build_vector_stores(chunks, propositions)\n",
    "    \n",
    "    results = []  # 전체 평가 결과 저장 리스트\n",
    "    \n",
    "    # 쿼리별 테스트 실행\n",
    "    for i, query in enumerate(test_queries):\n",
    "        print(f\"\\n\\n***쿼리 {i+1}/{len(test_queries)} 테스트 중***\")\n",
    "        print(f\"질문: {query}\")\n",
    "        \n",
    "        # 청크 기반 vs 명제 기반 검색 결과 비교\n",
    "        retrieval_results = compare_retrieval_approaches(query, chunk_store, prop_store)\n",
    "        \n",
    "        # 명제 기반 결과로 응답 생성\n",
    "        print(\"\\n명제 기반 응답 생성 중...\")\n",
    "        prop_response = generate_response(\n",
    "            query, \n",
    "            retrieval_results[\"proposition_results\"], \n",
    "            \"proposition\"\n",
    "        )\n",
    "        \n",
    "        # 청크 기반 결과로 응답 생성\n",
    "        print(\"청크 기반 응답 생성 중...\")\n",
    "        chunk_response = generate_response(\n",
    "            query, \n",
    "            retrieval_results[\"chunk_results\"], \n",
    "            \"chunk\"\n",
    "        )\n",
    "        \n",
    "        # 정답이 있다면 포함\n",
    "        reference = None\n",
    "        if reference_answers and i < len(reference_answers):\n",
    "            reference = reference_answers[i]\n",
    "        \n",
    "        # 두 응답 평가\n",
    "        print(\"\\n응답 비교 평가 중...\")\n",
    "        evaluation = evaluate_responses(query, prop_response, chunk_response, reference)\n",
    "        \n",
    "        # 현재 쿼리 결과 정리\n",
    "        query_result = {\n",
    "            \"query\": query,\n",
    "            \"proposition_results\": retrieval_results[\"proposition_results\"],\n",
    "            \"chunk_results\": retrieval_results[\"chunk_results\"],\n",
    "            \"proposition_response\": prop_response,\n",
    "            \"chunk_response\": chunk_response,\n",
    "            \"reference_answer\": reference,\n",
    "            \"evaluation\": evaluation\n",
    "        }\n",
    "        results.append(query_result)\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(\"\\n***명제 기반 응답***\")\n",
    "        print(prop_response)\n",
    "        print(\"\\n***청크 기반 응답***\")\n",
    "        print(chunk_response)\n",
    "        print(\"\\n***평가 결과***\")\n",
    "        print(evaluation)\n",
    "    \n",
    "    # 전체 종합 분석 생성\n",
    "    print(\"\\n\\n***전체 분석 생성 중***\")\n",
    "    overall_analysis = generate_overall_analysis(results)\n",
    "    print(\"\\n\" + overall_analysis)\n",
    "    \n",
    "    # 최종 결과 반환\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"overall_analysis\": overall_analysis,\n",
    "        \"proposition_count\": len(propositions),\n",
    "        \"chunk_count\": len(chunks)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_overall_analysis(results):\n",
    "    \"\"\"\n",
    "    명제 기반 vs 청크 기반 접근 방식의 종합 분석을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        results (List[Dict]): 각 테스트 쿼리의 평가 결과 리스트\n",
    "\n",
    "    Returns:\n",
    "        str: 종합 분석 결과 (자연어 텍스트)\n",
    "    \"\"\"\n",
    "    # 시스템 프롬프트: LLM에게 평가자 역할 및 비교 관점을 지시\n",
    "    system_prompt = \"\"\"당신은 정보 검색 시스템을 평가하는 전문가입니다.\n",
    "    여러 테스트 쿼리를 바탕으로, RAG(Retrieval-Augmented Generation) 시스템에서 \n",
    "    명제 기반 검색(proposition-based retrieval)과 청크 기반 검색(chunk-based retrieval)을 비교하여 종합 분석을 제공하세요.\n",
    "\n",
    "    다음 사항에 중점을 두어 평가하십시오:\n",
    "    1. 명제 기반 검색이 더 우수한 경우\n",
    "    2. 청크 기반 검색이 더 우수한 경우\n",
    "    3. 각 접근 방식의 전반적인 강점과 약점\n",
    "    4. 각 접근 방식을 어떤 상황에서 사용하는 것이 좋은지에 대한 추천\"\"\"\n",
    "\n",
    "\n",
    "    # 각 쿼리 평가의 요약 내용을 생성\n",
    "    evaluations_summary = \"\"\n",
    "    for i, result in enumerate(results):\n",
    "        evaluations_summary += f\"Query {i+1}: {result['query']}\\n\"\n",
    "        evaluations_summary += f\"Evaluation Summary: {result['evaluation'][:200]}...\\n\\n\"  # 앞부분만 요약 출력\n",
    "\n",
    "    # 사용자 프롬프트: 전체 평가 요약을 기반으로 종합 분석 요청\n",
    "    user_prompt = f\"\"\"다음은 명제 기반 검색(proposition-based retrieval)과 청크 기반 검색(chunk-based retrieval)에 대한 {len(results)}개의 쿼리 평가 결과입니다. \n",
    "    이 평가들을 바탕으로 두 접근 방식에 대한 종합적인 비교 분석을 작성해 주세요:\n",
    "\n",
    "    {evaluations_summary}\n",
    "\n",
    "    명제 기반 검색과 청크 기반 검색의 상대적인 강점과 약점을 중심으로,\n",
    "    RAG(Retrieval-Augmented Generation) 시스템에서 두 방식의 성능을 포괄적으로 분석해 주세요.\"\"\"\n",
    "\n",
    "\n",
    "    # LLM을 통해 종합 분석 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0  # 일관성 있는 분석을 위해 창의성 최소화\n",
    "    )\n",
    "    \n",
    "    # 생성된 분석 결과 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Proposition Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***명제 기반 청크화 평가 시작***\n",
      "\n",
      "Total 24개의 텍스트 청크가 생성되었습니다.\n",
      "청크로부터 명제를 생성 중...\n",
      "1/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 20\n",
      "2/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 27\n",
      "3/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 17\n",
      "4/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 45\n",
      "5/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 39\n",
      "6/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 24\n",
      "7/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 27\n",
      "8/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 41\n",
      "9/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 23\n",
      "10/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 44\n",
      "11/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 33\n",
      "12/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 34\n",
      "13/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 36\n",
      "14/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 38\n",
      "15/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 36\n",
      "16/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 41\n",
      "17/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 33\n",
      "18/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 30\n",
      "19/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 44\n",
      "20/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 40\n",
      "21/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 35\n",
      "22/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 28\n",
      "23/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 32\n",
      "24/24 번째 청크 처리 중...\n",
      "생성된 명제 수: 21\n",
      "\n",
      "명제 품질 평가 중...\n",
      "1/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 인공 지능은 종종 신화와 소설에 묘사되었다....\n",
      "11/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 인공 지능의 편견에 대한 우려가 커지고 있다....\n",
      "21/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 모델링 도구의 개발은 AI의 응용 분야를 보여준다....\n",
      "품질 기준 미달 명제: AI의 응용 분야는 광범위하고 성장하고 있다....\n",
      "품질 기준 미달 명제: 편견에 대한 우려는 커지고 있다....\n",
      "품질 기준 미달 명제: 머신 러닝 알고리즘은 예측을 수행한다....\n",
      "31/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 클러스터링은 비지도 학습의 일반적인 기술이다....\n",
      "품질 기준 미달 명제: 차원 축소는 비지도 학습의 일반적인 기술이다....\n",
      "41/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 강화 학습에서 에이전트는 보상 또는 페널티의 형태로 피드백을 받는다....\n",
      "품질 기준 미달 명제: 강화 학습은 게임 플레이에서 사용된다....\n",
      "품질 기준 미달 명제: 강화 학습은 로봇 공학에서 사용된다....\n",
      "품질 기준 미달 명제: 강화 학습은 리소스 관리에서 사용된다....\n",
      "품질 기준 미달 명제: 레이, 로봇 공학 및 리소스 관리에서 사용됩니다....\n",
      "51/788 번째 명제 평가 중...\n",
      "61/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI의 적용 분야는 방대합니다....\n",
      "품질 기준 미달 명제: 인공 지능은 주행 자동차에서 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 의료 영상에서 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 감시 시스템에서 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능의 적용 분야는 방대합니다....\n",
      "품질 기준 미달 명제: 인공 지능의 적용 분야는 다양한 산업과 영역에서 계속 확장되고 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능은 헬스케어 분야에서 의료 진단에 사용됩니다....\n",
      "71/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 인공 지능은 헬스케어 분야에서 신약 개발에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 헬스케어 분야에서 로봇 수술에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 금융 분야에서 알고리즘 트레이딩에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 금융 분야에서 리스크 관리에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 금융 분야에서 고객 서비스에 사용됩니다....\n",
      "81/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 인공 지능 알고리즘은 대규모 데이터 세트를 분석할 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능 알고리즘은 패턴을 파악할 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능 알고리즘은 시장 동향을 예측할 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능은 교통 분야에서 자율주행차에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 교통 분야에서 교통 최적화 시스템에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 교통 분야에서 물류 관리에 사용됩니다....\n",
      "91/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 인공 지능은 리테일 업계에서 재고 관리에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 리테일 업계에서 고객 서비스 챗봇에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 리테일 업계에서 공급망 최적화에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능 기반 시스템은 고객 데이터를 분석할 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능 기반 시스템은 수요를 예측할 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능 기반 시스템은 제안을 개인화할 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능은 제조업에서 품질 관리에 사용됩니다....\n",
      "101/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 인공 지능은 제조업에서 프로세스 최적화에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 제조업에서 로봇 공학에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능 기반 시스템은 장비를 모니터링할 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능 기반 시스템은 이상 징후를 감지할 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능 기반 시스템은 작업을 자동화할 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능 기반 시스템은 효율성을 높일 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능 기반 시스템은 비용을 절감할 수 있습니다....\n",
      "품질 기준 미달 명제: 인공 지능은 교육 분야에서 개인화된 학습 플랫폼에 사용됩니다....\n",
      "품질 기준 미달 명제: 인공 지능은 교육 분야에서 자동화된 채점 시스템에 사용됩니다....\n",
      "품질 기준 미달 명제: 스템은 장비를 모니터링한다....\n",
      "111/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 스템은 이상 징후를 감지한다....\n",
      "품질 기준 미달 명제: 스템은 작업을 자동화한다....\n",
      "품질 기준 미달 명제: 스템은 효율성을 높인다....\n",
      "품질 기준 미달 명제: 스템은 비용을 절감할 수 있다....\n",
      "품질 기준 미달 명제: AI는 자동화된 채점 시스템을 제공한다....\n",
      "품질 기준 미달 명제: AI는 가상 튜터를 제공한다....\n",
      "품질 기준 미달 명제: AI 기반 도구는 피드백을 제공한다....\n",
      "121/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI 알고리즘은 사용자 선호도를 분석한다....\n",
      "품질 기준 미달 명제: AI 알고리즘은 영화, 음악, 게임을 추천한다....\n",
      "품질 기준 미달 명제: AI 알고리즘은 사용자 참여도를 높인다....\n",
      "품질 기준 미달 명제: AI는 사이버 보안에서 위협을 탐지한다....\n",
      "품질 기준 미달 명제: AI는 사이버 보안에서 대응한다....\n",
      "품질 기준 미달 명제: AI는 네트워크 트래픽을 분석한다....\n",
      "131/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI는 취약점을 식별한다....\n",
      "품질 기준 미달 명제: AI의 급속한 발전과 보급은 사회적 우려를 불러일으킨다....\n",
      "141/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 개인정보 보호는 중요한 문제이다....\n",
      "품질 기준 미달 명제: 보안은 중요한 문제이다....\n",
      "151/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI 시스템이 더욱 자율화되고 있다....\n",
      "품질 기준 미달 명제: AI 시스템의 통제에 대한 의문이 제기되고 있다....\n",
      "품질 기준 미달 명제: AI 시스템의 책임에 대한 의문이 제기되고 있다....\n",
      "품질 기준 미달 명제: AI 시스템의 의도하지 않은 결과의 발생 가능성에 대한 의문이 제기되고 있다....\n",
      "161/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI 배포를 위한 명확한 가이드라인을 수립하는 것이 중요하다....\n",
      "품질 기준 미달 명제: AI의 미래는 다양한 영역에서 지속적인 발전으로 특징지어질 것이다....\n",
      "품질 기준 미달 명제: AI의 미래는 폭넓은 도입으로 특징지어질 것이다....\n",
      "171/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 엣지에서의 AI는 개인정보 보호를 개선한다....\n",
      "181/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 양자 컴퓨팅은 신약 개발 분야에서 획기적인 발전을 이룰 수 있는 잠재력을 가지고 있다....\n",
      "품질 기준 미달 명제: 양자 컴퓨팅은 최적화 분야에서 획기적인 발전을 이룰 수 있는 잠재력을 가지고 있다....\n",
      "품질 기준 미달 명제: AI 도구 개발은 인간의 능력을 보강한다....\n",
      "품질 기준 미달 명제: AI 도구 개발은 의사 결정을 지원한다....\n",
      "품질 기준 미달 명제: AI 도구 개발은 생산성을 향상시킨다....\n",
      "품질 기준 미달 명제: AI는 기후 변화 문제를 해결하는 데 사용되고 있다....\n",
      "191/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI는 빈곤 문제를 해결하는 데 사용되고 있다....\n",
      "품질 기준 미달 명제: AI는 의료 격차 문제를 해결하는 데 사용되고 있다....\n",
      "품질 기준 미달 명제: 윤리 가이드라인 수립은 AI의 책임감 있는 개발을 보장하는 데 필요하다....\n",
      "품질 기준 미달 명제: 편향성 문제 해결은 AI의 책임감 있는 개발을 보장하는 데 필요하다....\n",
      "품질 기준 미달 명제: 공정성 문제 해결은 AI의 책임감 있는 개발을 보장하는 데 필요하다....\n",
      "품질 기준 미달 명제: 개인정보 보호는 AI의 책임감 있는 개발을 보장하는 데 필요하다....\n",
      "품질 기준 미달 명제: 보안 문제 해결은 AI의 책임감 있는 개발을 보장하는 데 필요하다....\n",
      "품질 기준 미달 명제: AI의 필요성이 점점 더 커질 것이다....\n",
      "201/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 윤리 가이드라인 수립이 필요하다....\n",
      "품질 기준 미달 명제: 편향성 문제 해결이 필요하다....\n",
      "품질 기준 미달 명제: 공정성 문제 해결이 필요하다....\n",
      "품질 기준 미달 명제: 개인정보 보호가 필요하다....\n",
      "품질 기준 미달 명제: 보안 보호가 필요하다....\n",
      "품질 기준 미달 명제: AI의 핵심 개념을 이해하는 것이 중요하다....\n",
      "품질 기준 미달 명제: AI의 응용 분야를 이해하는 것이 중요하다....\n",
      "품질 기준 미달 명제: AI의 윤리적 의미를 이해하는 것이 중요하다....\n",
      "품질 기준 미달 명제: AI의 향후 방향성을 이해하는 것이 중요하다....\n",
      "211/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 지속적인 연구가 필요하다....\n",
      "품질 기준 미달 명제: 책임감 있는 개발이 필요하다....\n",
      "품질 기준 미달 명제: 신중한 거버넌스가 필요하다....\n",
      "품질 기준 미달 명제: AI의 잠재력을 최대한 실현하는 것이 중요하다....\n",
      "품질 기준 미달 명제: AI의 위험을 완화하는 것이 중요하다....\n",
      "품질 기준 미달 명제: 인공지능과 로봇공학의 통합이 이루어지고 있다....\n",
      "품질 기준 미달 명제: AI 기반 로봇은 제조 분야에서 사용된다....\n",
      "품질 기준 미달 명제: AI 기반 로봇은 의료 분야에서 사용된다....\n",
      "품질 기준 미달 명제: AI 기반 로봇은 물류 분야에서 사용된다....\n",
      "221/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI 기반 로봇은 탐사 분야에서 사용된다....\n",
      "품질 기준 미달 명제: 산업용 로봇은 용접 작업을 위해 사용된다....\n",
      "품질 기준 미달 명제: 산업용 로봇은 도장 작업을 위해 사용된다....\n",
      "품질 기준 미달 명제: 산업용 로봇은 조립 작업을 위해 사용된다....\n",
      "품질 기준 미달 명제: 산업용 로봇은 자재 취급 작업을 위해 사용된다....\n",
      "품질 기준 미달 명제: AI는 로봇의 정밀도를 향상시킨다....\n",
      "품질 기준 미달 명제: AI는 로봇의 효율성을 향상시킨다....\n",
      "품질 기준 미달 명제: AI는 로봇의 적응력을 향상시킨다....\n",
      "231/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 서비스 로봇은 배달 업무에서 사람을 보조한다....\n",
      "품질 기준 미달 명제: 서비스 로봇은 고객 서비스 업무에서 사람을 보조한다....\n",
      "품질 기준 미달 명제: AI를 통해 서비스 로봇은 자율적으로 탐색할 수 있다....\n",
      "품질 기준 미달 명제: AI를 통해 서비스 로봇은 사람과 상호 작용할 수 있다....\n",
      "품질 기준 미달 명제: AI를 통해 서비스 로봇은 작업을 수행할 수 있다....\n",
      "241/788 번째 명제 평가 중...\n",
      "251/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 강화 학습은 로봇이 작업을 수행하도록 훈련하는 방법입니다....\n",
      "261/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 컴퓨터 비전에는 물체 인식이 포함됩니다....\n",
      "품질 기준 미달 명제: 컴퓨터 비전에는 장면 이해가 포함됩니다....\n",
      "품질 기준 미달 명제: 컴퓨터 비전에는 장애물 회피가 포함됩니다....\n",
      "품질 기준 미달 명제: AI는 비즈니스 운영 혁신으로 효율성 향상을 가져온다....\n",
      "271/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI는 비즈니스 운영 혁신으로 의사 결정 개선을 가져온다....\n",
      "품질 기준 미달 명제: AI 기반 도구는 데이터를 분석한다....\n",
      "품질 기준 미달 명제: AI 기반 챗봇은 고객 참여도를 향상시킨다....\n",
      "품질 기준 미달 명제: AI 기반 추천 엔진은 고객 만족도를 향상시킨다....\n",
      "281/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI 기반 감정 분석 도구는 고객 만족도를 향상시킨다....\n",
      "품질 기준 미달 명제: AI는 수요를 예측한다....\n",
      "품질 기준 미달 명제: AI는 재고를 관리한다....\n",
      "품질 기준 미달 명제: AI는 물류를 간소화한다....\n",
      "품질 기준 미달 명제: AI 기반 시스템은 낭비를 줄인다....\n",
      "품질 기준 미달 명제: AI는 인재 확보를 위해 활용된다....\n",
      "품질 기준 미달 명제: AI는 직원 온보딩을 위해 활용된다....\n",
      "291/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI는 성과 관리를 위해 활용된다....\n",
      "품질 기준 미달 명제: AI는 교육을 위해 활용된다....\n",
      "품질 기준 미달 명제: AI 기반 도구는 교육 프로그램을 개인화한다....\n",
      "품질 기준 미달 명제: AI 기반 도구는 직원 참여에 대한 인사이트를 제공한다....\n",
      "품질 기준 미달 명제: AI 기반 도구는 직원 유지에 대한 인사이트를 제공한다....\n",
      "품질 기준 미달 명제: AI는 고객 데이터를 분석한다....\n",
      "품질 기준 미달 명제: AI는 판매 추세를 예측한다....\n",
      "301/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI 기반 도구는 광고 지출을 최적화한다....\n",
      "품질 기준 미달 명제: AI는 금융 서비스에서 사기 탐지를 수행한다....\n",
      "품질 기준 미달 명제: AI는 금융 서비스에서 위험 관리를 수행한다....\n",
      "품질 기준 미달 명제: AI는 금융 서비스에서 알고리즘 트레이딩을 수행한다....\n",
      "품질 기준 미달 명제: AI는 금융 서비스에서 고객 서비스를 수행한다....\n",
      "품질 기준 미달 명제: 도구는 타겟팅을 개선한다....\n",
      "품질 기준 미달 명제: 도구는 광고 지출을 최적화한다....\n",
      "품질 기준 미달 명제: 도구는 고객 세분화를 강화한다....\n",
      "311/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI는 금융 서비스에서 고객 서비스에 사용된다....\n",
      "품질 기준 미달 명제: AI 기반 시스템은 패턴을 파악한다....\n",
      "품질 기준 미달 명제: AI는 일부 업무를 자동화할 수 있다....\n",
      "321/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI는 새로운 기회를 창출할 수 있다....\n",
      "품질 기준 미달 명제: AI는 기존 역할을 변화시킬 수 있다....\n",
      "품질 기준 미달 명제: AI 도구는 인간의 역량을 강화한다....\n",
      "품질 기준 미달 명제: AI 도구는 일상적인 작업을 자동화한다....\n",
      "331/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI의 개발과 배포는 AI 교육 분야에서 새로운 일자리를 창출한다....\n",
      "품질 기준 미달 명제: 새로운 역할에는 전문 지식이 필요하다....\n",
      "품질 기준 미달 명제: AI 시스템의 공정성을 보장하는 것이 중요하다....\n",
      "품질 기준 미달 명제: AI 시스템의 투명성을 보장하는 것이 중요하다....\n",
      "품질 기준 미달 명제: AI 시스템의 책임성을 보장하는 것이 중요하다....\n",
      "품질 기준 미달 명제: 근로자의 권리를 보장하는 것이 중요하다....\n",
      "341/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 인공지능 시스템의 공정성을 보장해야 한다....\n",
      "품질 기준 미달 명제: 근로자의 권리를 보호해야 한다....\n",
      "품질 기준 미달 명제: 개인정보를 보호해야 한다....\n",
      "351/788 번째 명제 평가 중...\n",
      "361/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 인공지능은 스크립트 작성을 위해 사용된다....\n",
      "품질 기준 미달 명제: 인공지능은 생산성을 향상시킬 수 있다....\n",
      "품질 기준 미달 명제: 인공지능은 창의성을 향상시킬 수 있다....\n",
      "품질 기준 미달 명제: 인공지능은 대규모 데이터 세트를 분석할 수 있다....\n",
      "품질 기준 미달 명제: 인공지능은 패턴을 파악할 수 있다....\n",
      "품질 기준 미달 명제: 인공지능은 새로운 아이디어를 창출할 수 있다....\n",
      "371/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 인공지능 기반 도구는 연구 개발에 사용된다....\n",
      "품질 기준 미달 명제: 인공지능 기반 도구는 문제 해결에 사용된다....\n",
      "품질 기준 미달 명제: 품 디자인은 문제 해결에 사용됩니다....\n",
      "품질 기준 미달 명제: AI 기반 플랫폼은 피드백을 제공합니다....\n",
      "품질 기준 미달 명제: AI 기반 플랫폼은 진도를 제공합니다....\n",
      "381/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI 기반 가상 튜터는 질문에 답합니다....\n",
      "품질 기준 미달 명제: AI 기반 가상 튜터는 안내를 제공합니다....\n",
      "품질 기준 미달 명제: AI 기반 도구는 교육에 대한 접근성을 높입니다....\n",
      "품질 기준 미달 명제: AI 기반 도구는 학습 성과를 개선합니다....\n",
      "391/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI 기반 시스템은 에세이를 평가합니다....\n",
      "품질 기준 미달 명제: AI 기반 시스템은 과제를 평가합니다....\n",
      "품질 기준 미달 명제: AI 기반 시스템은 시험을 평가합니다....\n",
      "품질 기준 미달 명제: 교육 데이터 마이닝은 패턴을 파악합니다....\n",
      "401/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: 교육 데이터 마이닝은 교육 전략을 수립할 수 있습니다....\n",
      "품질 기준 미달 명제: AI는 의료 이미지를 분석합니다....\n",
      "품질 기준 미달 명제: AI는 환자 결과를 예측합니다....\n",
      "품질 기준 미달 명제: AI 기반 도구는 정확성을 향상시킵니다....\n",
      "품질 기준 미달 명제: AI 기반 도구는 효율성을 향상시킵니다....\n",
      "411/788 번째 명제 평가 중...\n",
      "품질 기준 미달 명제: AI 기반 도구는 정확성을 향상시킨다....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m reference_answers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI 개발의 주요 윤리적 문제에는 편견과 공정성, 개인정보 보호, 투명성, 책임성, 안전, 오용 또는 유해한 애플리케이션의 가능성 등이 있습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 평가 실행 (엔드 투 엔드: 문서 처리 → 명제 생성 → 벡터 저장소 → 검색 → 응답 생성 → 평가)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m run_proposition_chunking_evaluation(\n\u001b[1;32m     16\u001b[0m     pdf_path\u001b[38;5;241m=\u001b[39mpdf_path,\n\u001b[1;32m     17\u001b[0m     test_queries\u001b[38;5;241m=\u001b[39mtest_queries,\n\u001b[1;32m     18\u001b[0m     reference_answers\u001b[38;5;241m=\u001b[39mreference_answers\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 전체 분석 결과 출력\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m***Overall Analysis***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 16\u001b[0m, in \u001b[0;36mrun_proposition_chunking_evaluation\u001b[0;34m(pdf_path, test_queries, reference_answers)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***명제 기반 청크화 평가 시작***\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 문서 처리 → 청크 및 명제 생성\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m chunks, propositions \u001b[38;5;241m=\u001b[39m process_document_into_propositions(pdf_path)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 벡터 저장소 구축 (청크용, 명제용)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m chunk_store, prop_store \u001b[38;5;241m=\u001b[39m build_vector_stores(chunks, propositions)\n",
      "Cell \u001b[0;32mIn[24], line 58\u001b[0m, in \u001b[0;36mprocess_document_into_propositions\u001b[0;34m(pdf_path, chunk_size, chunk_overlap, quality_thresholds)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_propositions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 번째 명제 평가 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# 해당 명제의 품질 점수 평가\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m scores \u001b[38;5;241m=\u001b[39m evaluate_proposition(prop[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], prop[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_text\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     59\u001b[0m prop[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m scores\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# 모든 기준 점수를 통과하는지 확인\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 91\u001b[0m, in \u001b[0;36mevaluate_proposition\u001b[0;34m(proposition, original_text)\u001b[0m\n\u001b[1;32m     84\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mProposition: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproposition\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124mOriginal Text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_text\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[38;5;124m평가 점수를 JSON 형식으로 제공해 주세요.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# LLM을 호출하여 평가 점수 생성\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     92\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     94\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt},\n\u001b[1;32m     95\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt}\n\u001b[1;32m     96\u001b[0m     ],\n\u001b[1;32m     97\u001b[0m     response_format\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m},  \u001b[38;5;66;03m# JSON 형식 응답 요청\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# 일관된 평가를 위해 창의성 최소화\u001b[39;00m\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# 모델 응답에서 JSON 파싱 시도\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    916\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    917\u001b[0m             {\n\u001b[1;32m    918\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    919\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    920\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m    921\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    922\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    923\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    924\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    925\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    926\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m    927\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    928\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    929\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m    930\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[1;32m    933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m    935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m    938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m    940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m    942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[1;32m    949\u001b[0m             },\n\u001b[1;32m    950\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    951\u001b[0m         ),\n\u001b[1;32m    952\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    953\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    954\u001b[0m         ),\n\u001b[1;32m    955\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    956\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    957\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    958\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    920\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    921\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    922\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    923\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    924\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m    925\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    956\u001b[0m         request,\n\u001b[1;32m    957\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    961\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m    927\u001b[0m     request,\n\u001b[1;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    931\u001b[0m )\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m    955\u001b[0m         request,\n\u001b[1;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    958\u001b[0m     )\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 처리할 AI 정보 문서의 경로\n",
    "pdf_path = \"dataset/AI_Understanding.pdf\"\n",
    "\n",
    "# AI의 다양한 측면을 평가하기 위한 테스트 쿼리 정의 (현재는 1개 사용)\n",
    "test_queries = [\n",
    "    \"AI 개발의 주요 윤리적 문제는 무엇인가요?\",\n",
    "]\n",
    "\n",
    "# 명제 기반 vs 청크 기반 응답의 정확도 비교를 위한 기준 정답 (Reference Answers)\n",
    "reference_answers = [\n",
    "    \"AI 개발의 주요 윤리적 문제에는 편견과 공정성, 개인정보 보호, 투명성, 책임성, 안전, 오용 또는 유해한 애플리케이션의 가능성 등이 있습니다.\",\n",
    "]\n",
    "\n",
    "# 평가 실행 (엔드 투 엔드: 문서 처리 → 명제 생성 → 벡터 저장소 → 검색 → 응답 생성 → 평가)\n",
    "evaluation_results = run_proposition_chunking_evaluation(\n",
    "    pdf_path=pdf_path,\n",
    "    test_queries=test_queries,\n",
    "    reference_answers=reference_answers\n",
    ")\n",
    "\n",
    "# 전체 분석 결과 출력\n",
    "print(\"\\n\\n***Overall Analysis***\")\n",
    "print(evaluation_results[\"overall_analysis\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Relevant Segment Extraction (RSE) for Enhanced RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Text from a PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트를 추출합니다.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): PDF 파일의 경로입니다.\n",
    "\n",
    "    Returns:\n",
    "    str: PDF에서 추출한 텍스트.\n",
    "    \"\"\"\n",
    "    # PDF 파일 열기\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\" # 추출된 텍스트를 저장할 빈 문자열을 초기화합니다.\n",
    "\n",
    "    # PDF의 각 페이지를 반복합니다.\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num] # 페이지 가져오기\n",
    "        text = page.get_text(\"text\") # 페이지에서 텍스트 추출\n",
    "        all_text += text # 추출한 텍스트를 all_text 문자열에 추가합니다.\n",
    "\n",
    "    return all_text # 추출된 텍스트를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking the Extracted Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=800, overlap=0):\n",
    "    \"\"\"\n",
    "    텍스트를 겹침(overlap) 없이 일정한 크기로 분할합니다.\n",
    "    RSE(Retrieval Segment Evaluation)에서는 겹치지 않는 청크가 일반적으로 필요합니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 분할할 원본 텍스트\n",
    "        chunk_size (int): 각 청크의 문자 길이 (기본값: 800자)\n",
    "        overlap (int): 청크 간 겹치는 문자 수 (기본값: 0)\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: 분할된 텍스트 청크 리스트\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "\n",
    "    # 문자 기준으로 일정 간격마다 슬라이싱하며 청크 생성\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunk = text[i:i + chunk_size]\n",
    "        if chunk:  # 빈 청크가 아닌 경우에만 추가\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Simple Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    NumPy를 활용한 간단한 벡터 저장소 구현체입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, dimension=1536):\n",
    "        \"\"\"\n",
    "        벡터 저장소 초기화\n",
    "        \n",
    "        Args:\n",
    "            dimension (int): 임베딩 벡터의 차원 수\n",
    "        \"\"\"\n",
    "        self.dimension = dimension\n",
    "        self.vectors = []     # 임베딩 벡터 리스트\n",
    "        self.documents = []   # 문서(청크) 리스트\n",
    "        self.metadata = []    # 각 문서의 메타데이터 리스트\n",
    "\n",
    "    def add_documents(self, documents, vectors=None, metadata=None):\n",
    "        \"\"\"\n",
    "        문서와 벡터를 벡터 저장소에 추가\n",
    "        \n",
    "        Args:\n",
    "            documents (List[str]): 문서 청크 리스트\n",
    "            vectors (List[List[float]], optional): 각 문서의 임베딩 벡터 리스트\n",
    "            metadata (List[Dict], optional): 각 문서에 대한 메타데이터 리스트\n",
    "        \"\"\"\n",
    "        if vectors is None:\n",
    "            vectors = [None] * len(documents)\n",
    "\n",
    "        if metadata is None:\n",
    "            metadata = [{} for _ in range(len(documents))]\n",
    "\n",
    "        for doc, vec, meta in zip(documents, vectors, metadata):\n",
    "            self.documents.append(doc)\n",
    "            self.vectors.append(vec)\n",
    "            self.metadata.append(meta)\n",
    "\n",
    "    def search(self, query_vector, top_k=5):\n",
    "        \"\"\"\n",
    "        가장 유사한 문서를 검색 (코사인 유사도 기준)\n",
    "        \n",
    "        Args:\n",
    "            query_vector (List[float]): 질의에 대한 임베딩 벡터\n",
    "            top_k (int): 반환할 상위 결과 개수\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: 문서, 유사도 점수, 메타데이터가 포함된 결과 리스트\n",
    "        \"\"\"\n",
    "        if not self.vectors or not self.documents:\n",
    "            return []\n",
    "\n",
    "        # 질의 벡터를 NumPy 배열로 변환\n",
    "        query_array = np.array(query_vector)\n",
    "\n",
    "        # 각 벡터와의 코사인 유사도 계산\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            if vector is not None:\n",
    "                similarity = np.dot(query_array, vector) / (\n",
    "                    np.linalg.norm(query_array) * np.linalg.norm(vector)\n",
    "                )\n",
    "                similarities.append((i, similarity))\n",
    "\n",
    "        # 유사도 기준으로 내림차순 정렬\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 상위 top_k 결과 추출\n",
    "        results = []\n",
    "        for i, score in similarities[:top_k]:\n",
    "            results.append({\n",
    "                \"document\": self.documents[i],\n",
    "                \"score\": float(score),\n",
    "                \"metadata\": self.metadata[i]\n",
    "            })\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Embeddings for Text Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_embeddings(texts, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    텍스트 리스트에 대해 임베딩 벡터를 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        texts (List[str]): 임베딩할 텍스트들의 리스트\n",
    "        model (str): 사용할 임베딩 모델 이름\n",
    "        \n",
    "    Returns:\n",
    "        List[List[float]]: 임베딩 벡터 리스트\n",
    "    \"\"\"\n",
    "    if not texts:\n",
    "        return []  # 텍스트가 없으면 빈 리스트 반환\n",
    "\n",
    "    # 긴 리스트일 경우 배치 단위로 처리\n",
    "    batch_size = 100  # API 제한에 따라 조정 가능\n",
    "    all_embeddings = []  # 전체 임베딩을 저장할 리스트 초기화\n",
    "\n",
    "    # 텍스트 리스트를 배치 단위로 나눠 임베딩 처리\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]  # 현재 배치 추출\n",
    "\n",
    "        # 지정된 모델을 사용하여 배치 임베딩 생성\n",
    "        response = client.embeddings.create(\n",
    "            input=batch,\n",
    "            model=model\n",
    "        )\n",
    "\n",
    "        # 응답에서 임베딩 벡터 추출\n",
    "        batch_embeddings = [item.embedding for item in response.data]\n",
    "        all_embeddings.extend(batch_embeddings)  # 전체 리스트에 추가\n",
    "\n",
    "    return all_embeddings  # 모든 임베딩 결과 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Documents with RSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_document(pdf_path, chunk_size=800):\n",
    "    \"\"\"\n",
    "    RSE(Retrieval Segment Evaluation) 또는 RAG에 사용할 수 있도록 문서를 처리합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF 문서의 경로.\n",
    "        chunk_size (int): 각 청크의 문자 길이.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], SimpleVectorStore, Dict]:\n",
    "            - 분할된 텍스트 청크 리스트.\n",
    "            - 벡터 저장소 객체(SimpleVectorStore).\n",
    "            - 문서 정보 (청크와 소스 경로 포함).\n",
    "    \"\"\"\n",
    "    print(\"문서에서 텍스트를 추출 중...\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    print(\"텍스트를 중첩 없이 청크 단위로 분할 중...\")\n",
    "    chunks = chunk_text(text, chunk_size=chunk_size, overlap=0)\n",
    "    print(f\"{len(chunks)}개의 청크가 생성되었습니다.\")\n",
    "\n",
    "    print(\"청크 임베딩을 생성 중...\")\n",
    "    chunk_embeddings = create_embeddings(chunks)\n",
    "\n",
    "    # 벡터 저장소 생성\n",
    "    vector_store = SimpleVectorStore()\n",
    "\n",
    "    # 각 청크에 대한 메타데이터 생성\n",
    "    metadata = [{\"chunk_index\": i, \"source\": pdf_path} for i in range(len(chunks))]\n",
    "\n",
    "    # 청크와 임베딩을 저장소에 추가\n",
    "    vector_store.add_documents(chunks, chunk_embeddings, metadata)\n",
    "\n",
    "    # 문서 정보 저장 (재구성에 사용할 수 있음)\n",
    "    doc_info = {\n",
    "        \"chunks\": chunks,\n",
    "        \"source\": pdf_path,\n",
    "    }\n",
    "\n",
    "    return chunks, vector_store, doc_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSE Core Algorithm: Computing Chunk Values and Finding Best Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_chunk_values(query, chunks, vector_store, irrelevant_chunk_penalty=0.2):\n",
    "    \"\"\"\n",
    "    질의에 대한 관련성과 위치 정보를 바탕으로 각 청크의 가치를 계산합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질의\n",
    "        chunks (List[str]): 문서 청크 리스트\n",
    "        vector_store (SimpleVectorStore): 벡터 저장소 (청크 포함)\n",
    "        irrelevant_chunk_penalty (float): 관련 없는 청크에 부여할 감점 값\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: 각 청크에 대한 가치 점수 리스트\n",
    "    \"\"\"\n",
    "    # 질의 임베딩 생성\n",
    "    query_embedding = create_embeddings([query])[0]\n",
    "\n",
    "    # 벡터 저장소에서 모든 청크에 대한 유사도 검색 (최대 청크 수만큼)\n",
    "    num_chunks = len(chunks)\n",
    "    results = vector_store.search(query_embedding, top_k=num_chunks)\n",
    "\n",
    "    # 검색 결과로부터 청크 인덱스별 관련성 점수 매핑 생성\n",
    "    relevance_scores = {result[\"metadata\"][\"chunk_index\"]: result[\"score\"] for result in results}\n",
    "\n",
    "    # 각 청크에 대해 가치 점수 계산 (관련성 - 감점)\n",
    "    chunk_values = []\n",
    "    for i in range(num_chunks):\n",
    "        # 해당 청크의 관련성 점수가 없으면 기본값 0 사용\n",
    "        score = relevance_scores.get(i, 0.0)\n",
    "        # 감점 적용: 관련 없는 청크는 음수 값이 될 수 있음\n",
    "        value = score - irrelevant_chunk_penalty\n",
    "        chunk_values.append(value)\n",
    "\n",
    "    return chunk_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_segments(chunk_values, max_segment_length=20, total_max_length=30, min_segment_value=0.2):\n",
    "    \"\"\"\n",
    "    최대 합 부분 배열 알고리즘(변형)을 사용하여 가장 가치 있는 연속 청크 구간(세그먼트)을 탐색합니다.\n",
    "\n",
    "    Args:\n",
    "        chunk_values (List[float]): 각 청크에 대한 점수 또는 가치 리스트.\n",
    "        max_segment_length (int): 하나의 세그먼트가 가질 수 있는 최대 길이.\n",
    "        total_max_length (int): 전체 포함 가능한 청크 수의 최대 합.\n",
    "        min_segment_value (float): 세그먼트로 인정되기 위한 최소 점수 합계.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Tuple[int, int]], List[float]]: \n",
    "            - 세그먼트 리스트 (각각 시작 인덱스, 종료 인덱스 형태).\n",
    "            - 각 세그먼트의 총 점수 리스트.\n",
    "    \"\"\"\n",
    "    print(\"최적의 연속 세그먼트를 찾는 중...\")\n",
    "\n",
    "    best_segments = []         # 선택된 세그먼트 저장\n",
    "    segment_scores = []        # 각 세그먼트의 총 점수\n",
    "    total_included_chunks = 0  # 전체 포함된 청크 수 누적\n",
    "\n",
    "    # 전체 길이 제한에 도달할 때까지 반복 탐색\n",
    "    while total_included_chunks < total_max_length:\n",
    "        best_score = min_segment_value\n",
    "        best_segment = None\n",
    "\n",
    "        for start in range(len(chunk_values)):\n",
    "            # 이미 포함된 세그먼트와 겹치는 경우 제외\n",
    "            if any(start >= s[0] and start < s[1] for s in best_segments):\n",
    "                continue\n",
    "\n",
    "            # 가능한 세그먼트 길이 내에서 탐색\n",
    "            for length in range(1, min(max_segment_length, len(chunk_values) - start) + 1):\n",
    "                end = start + length\n",
    "\n",
    "                # 종료 지점이 기존 세그먼트와 겹치면 제외\n",
    "                if any(end > s[0] and end <= s[1] for s in best_segments):\n",
    "                    continue\n",
    "\n",
    "                segment_value = sum(chunk_values[start:end])\n",
    "\n",
    "                if segment_value > best_score:\n",
    "                    best_score = segment_value\n",
    "                    best_segment = (start, end)\n",
    "\n",
    "        # 가장 가치 있는 세그먼트를 추가\n",
    "        if best_segment:\n",
    "            best_segments.append(best_segment)\n",
    "            segment_scores.append(best_score)\n",
    "            total_included_chunks += best_segment[1] - best_segment[0]\n",
    "            print(f\"세그먼트 {best_segment} 발견 (점수: {best_score:.4f})\")\n",
    "        else:\n",
    "            break  # 더 이상 유효한 세그먼트 없음\n",
    "\n",
    "    # 시작 인덱스 기준 정렬\n",
    "    best_segments = sorted(best_segments, key=lambda x: x[0])\n",
    "\n",
    "    return best_segments, segment_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing and Using Segments for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reconstruct_segments(chunks, best_segments):\n",
    "    \"\"\"\n",
    "    선택된 청크 인덱스를 바탕으로 텍스트 세그먼트를 재조립합니다.\n",
    "    \n",
    "    Args:\n",
    "        chunks (List[str]): 전체 문서를 분할한 청크 리스트\n",
    "        best_segments (List[Tuple[int, int]]): (시작, 끝) 인덱스로 구성된 세그먼트 리스트\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: 재조립된 텍스트 세그먼트 리스트 (딕셔너리 형태 포함)\n",
    "    \"\"\"\n",
    "    reconstructed_segments = []  # 재조립된 세그먼트를 저장할 리스트\n",
    "\n",
    "    for start, end in best_segments:\n",
    "        # 해당 범위의 청크들을 연결하여 하나의 세그먼트 텍스트로 생성\n",
    "        segment_text = \" \".join(chunks[start:end])\n",
    "        \n",
    "        # 세그먼트 텍스트와 인덱스 범위를 함께 저장\n",
    "        reconstructed_segments.append({\n",
    "            \"text\": segment_text,\n",
    "            \"segment_range\": (start, end),\n",
    "        })\n",
    "\n",
    "    # 재조립된 세그먼트 리스트 반환\n",
    "    return reconstructed_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_segments_for_context(segments):\n",
    "    \"\"\"\n",
    "    LLM 입력용 문맥(context) 형식으로 세그먼트를 구성합니다.\n",
    "    \n",
    "    Args:\n",
    "        segments (List[Dict]): 세그먼트 딕셔너리들의 리스트\n",
    "        \n",
    "    Returns:\n",
    "        str: 포맷팅된 문맥 문자열\n",
    "    \"\"\"\n",
    "    context = []  # 포맷팅된 문맥 문자열 조각들을 담을 리스트 초기화\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        # 각 세그먼트에 대한 헤더 생성 (세그먼트 번호 및 청크 범위 표시)\n",
    "        segment_header = f\"SEGMENT {i+1} (Chunks {segment['segment_range'][0]}-{segment['segment_range'][1]-1}):\"\n",
    "        context.append(segment_header)          # 헤더 추가\n",
    "        context.append(segment['text'])         # 세그먼트 텍스트 추가\n",
    "        context.append(\"-\" * 80)                # 가독성을 위한 구분선 추가\n",
    "\n",
    "    # 리스트의 모든 요소를 두 줄 간격으로 이어붙여 최종 문맥 문자열 생성\n",
    "    return \"\\n\\n\".join(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Responses with RSE Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_response(query, context, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    주어진 질의와 문맥을 바탕으로 LLM 응답을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str): 사용자 질의.\n",
    "        context (str): 관련 세그먼트로 구성된 문맥 텍스트.\n",
    "        model (str): 사용할 LLM 모델 이름.\n",
    "\n",
    "    Returns:\n",
    "        str: 생성된 응답 텍스트.\n",
    "    \"\"\"\n",
    "    print(\"관련 세그먼트를 문맥으로 활용하여 응답을 생성합니다...\")\n",
    "\n",
    "    # 시스템 프롬프트: LLM의 역할 정의\n",
    "    system_prompt = \"\"\"당신은 제공된 문맥을 기반으로 질문에 답하는 유용한 AI 어시스턴트입니다.\n",
    "    문맥은 쿼리와 관련된 문서 세그먼트로 구성되어 있으며,\n",
    "    당신은 그 정보를 활용해 정확하고 포괄적인 답변을 생성해야 합니다.\n",
    "    만약 문맥에 해당 질문에 대한 직접적인 정보가 없다면, 그 사실을 명확히 언급하세요.\"\"\"\n",
    "\n",
    "    # 사용자 프롬프트: 문맥 + 질의\n",
    "    user_prompt = f\"\"\"\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {query}\n",
    "\n",
    "    위 문맥에 따라 가능한 한 구체적이고 유익한 답변을 작성해 주세요.\n",
    "    \"\"\"\n",
    "\n",
    "    # LLM 호출하여 응답 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete RSE Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_rse(pdf_path, query, chunk_size=800, irrelevant_chunk_penalty=0.2):\n",
    "    \"\"\"\n",
    "    Relevant Segment Extraction(RSE)을 포함한 RAG 파이프라인 전체 실행 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): 처리할 PDF 문서의 경로.\n",
    "        query (str): 사용자 질의.\n",
    "        chunk_size (int): 분할할 청크의 문자 수.\n",
    "        irrelevant_chunk_penalty (float): 관련 없는 청크에 부과할 감점 값.\n",
    "\n",
    "    Returns:\n",
    "        Dict: 다음 정보를 포함한 결과 딕셔너리:\n",
    "            - query: 사용자 질의.\n",
    "            - segments: 선택된 세그먼트 텍스트.\n",
    "            - response: LLM이 생성한 응답.\n",
    "    \"\"\"\n",
    "    print(\"\\n***RAG with Relevant Segment Extraction 시작***\")\n",
    "    print(f\"사용자 질문: {query}\")\n",
    "\n",
    "    # 1. 문서 전처리 (PDF → 텍스트 추출 → 청크 분할 → 임베딩 생성)\n",
    "    chunks, vector_store, doc_info = process_document(pdf_path, chunk_size)\n",
    "\n",
    "    # 2. 각 청크에 대해 쿼리 기반 관련성 점수 계산\n",
    "    print(\"\\n관련성 점수 계산 중...\")\n",
    "    chunk_values = calculate_chunk_values(\n",
    "        query=query,\n",
    "        chunks=chunks,\n",
    "        vector_store=vector_store,\n",
    "        irrelevant_chunk_penalty=irrelevant_chunk_penalty\n",
    "    )\n",
    "\n",
    "    # 3. 가장 높은 점수를 가진 연속 세그먼트 선택\n",
    "    best_segments, scores = find_best_segments(\n",
    "        chunk_values,\n",
    "        max_segment_length=20,\n",
    "        total_max_length=30,\n",
    "        min_segment_value=0.2\n",
    "    )\n",
    "\n",
    "    # 4. 선택된 세그먼트를 기반으로 문맥 구성\n",
    "    print(\"\\n세그먼트 재구성 중...\")\n",
    "    segments = reconstruct_segments(chunks, best_segments)\n",
    "\n",
    "    # 5. LLM 입력용 문맥 문자열 포맷팅\n",
    "    context = format_segments_for_context(segments)\n",
    "\n",
    "    # 6. 문맥 + 질의를 기반으로 응답 생성\n",
    "    response = generate_response(query, context)\n",
    "\n",
    "    # 7. 결과 정리\n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"segments\": segments,\n",
    "        \"response\": response\n",
    "    }\n",
    "\n",
    "    print(\"\\n***최종 응답 결과***\")\n",
    "    print(response)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with Standard Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standard_top_k_retrieval(pdf_path, query, k=10, chunk_size=800):\n",
    "    \"\"\"\n",
    "    상위 k개의 청크를 검색하여 문맥으로 사용하는 표준 RAG 방식입니다.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDF 문서 경로\n",
    "        query (str): 사용자 질의\n",
    "        k (int): 검색할 상위 관련 청크 개수\n",
    "        chunk_size (int): 청크 크기 (문자 단위)\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 질의, 검색된 청크, 생성된 응답이 포함된 결과\n",
    "    \"\"\"\n",
    "    print(\"\\n=== STARTING STANDARD TOP-K RETRIEVAL ===\")\n",
    "    print(f\"Query: {query}\")\n",
    "\n",
    "    # 문서 전처리: 텍스트 추출, 청크 분할, 임베딩 생성\n",
    "    chunks, vector_store, doc_info = process_document(pdf_path, chunk_size)\n",
    "\n",
    "    # 질의 임베딩 생성 후, 상위 k개 청크 검색\n",
    "    print(\"Creating query embedding and retrieving chunks...\")\n",
    "    query_embedding = create_embeddings([query])[0]\n",
    "    results = vector_store.search(query_embedding, top_k=k)\n",
    "\n",
    "    # 검색된 청크 텍스트만 추출\n",
    "    retrieved_chunks = [result[\"document\"] for result in results]\n",
    "\n",
    "    # 검색된 청크들을 문맥 문자열로 포맷팅\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"CHUNK {i+1}:\\n{chunk}\" \n",
    "        for i, chunk in enumerate(retrieved_chunks)\n",
    "    ])\n",
    "\n",
    "    # 문맥을 기반으로 LLM 응답 생성\n",
    "    response = generate_response(query, context)\n",
    "\n",
    "    # 결과 정리\n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"chunks\": retrieved_chunks,\n",
    "        \"response\": response\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== FINAL RESPONSE ===\")\n",
    "    print(response)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of RSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_methods(pdf_path, query, reference_answer=None):\n",
    "    \"\"\"\n",
    "    RSE 방식과 표준 Top-K 검색 방식을 비교 평가합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF 문서 경로.\n",
    "        query (str): 사용자 질문.\n",
    "        reference_answer (str, optional): 기준 정답 (있을 경우 응답 평가 수행).\n",
    "\n",
    "    Returns:\n",
    "        Dict: RSE 방식과 표준 방식의 결과를 포함한 딕셔너리.\n",
    "    \"\"\"\n",
    "    print(\"\\n========= 평가 시작 =========\\n\")\n",
    "\n",
    "    # 1. Relevant Segment Extraction 기반 RAG 실행\n",
    "    rse_result = rag_with_rse(pdf_path, query)\n",
    "\n",
    "    # 2. 표준 Top-K 검색 기반 RAG 실행\n",
    "    standard_result = standard_top_k_retrieval(pdf_path, query)\n",
    "\n",
    "    # 3. 기준 정답이 주어졌을 경우, 두 응답을 비교 평가\n",
    "    if reference_answer:\n",
    "        print(\"\\n=== 응답 비교 평가 ===\")\n",
    "\n",
    "        evaluation_prompt = f\"\"\"\n",
    "    Query: {query}\n",
    "\n",
    "    [Reference Answer]\n",
    "    {reference_answer}\n",
    "\n",
    "    [Standard Retrieval Response]\n",
    "    {standard_result['response']}\n",
    "\n",
    "    [Relevant Segment Extraction Response]\n",
    "    {rse_result['response']}\n",
    "\n",
    "    위 두 응답을 기준 정답과 비교하여 다음을 판단하세요:\n",
    "    1. 더 정확하고 포괄적인 응답은 무엇인가요?\n",
    "    2. 사용자 질문을 더 잘 해결한 응답은 어떤 것인가요?\n",
    "    3. 불필요하거나 관련 없는 정보를 덜 포함한 응답은 무엇인가요?\n",
    "\n",
    "    각 항목에 대해 근거를 명확히 설명한 후, 어느 방식이 더 우수했는지 종합적으로 평가하세요.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"기준 정답과 비교하여 응답 평가 중...\")\n",
    "\n",
    "        evaluation = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 RAG 응답을 공정하게 평가하는 시스템입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(\"\\n=== 평가 결과 ===\")\n",
    "        print(evaluation.choices[0].message.content)\n",
    "\n",
    "    return {\n",
    "        \"rse_result\": rse_result,\n",
    "        \"standard_result\": standard_result\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= 평가 시작 =========\n",
      "\n",
      "\n",
      "***RAG with Relevant Segment Extraction 시작***\n",
      "사용자 질문: '설명 가능한 AI(Explainable AI)'란 무엇이며, 왜 중요한가?\n",
      "문서에서 텍스트를 추출 중...\n",
      "텍스트를 중첩 없이 청크 단위로 분할 중...\n",
      "21개의 청크가 생성되었습니다.\n",
      "청크 임베딩을 생성 중...\n",
      "\n",
      "관련성 점수 계산 중...\n",
      "최적의 연속 세그먼트를 찾는 중...\n",
      "세그먼트 (0, 20) 발견 (점수: 5.5964)\n",
      "세그먼트 (20, 21) 발견 (점수: 0.2936)\n",
      "\n",
      "세그먼트 재구성 중...\n",
      "관련 세그먼트를 문맥으로 활용하여 응답을 생성합니다...\n",
      "\n",
      "***최종 응답 결과***\n",
      "설명 가능한 AI(Explainable AI, XAI)는 AI 시스템이 의사 결정을 내리는 방식을 투명하고 이해하기 쉽게 만드는 것을 목표로 하는 기술입니다. XAI는 AI 모델의 작동 원리를 설명하고, 사용자가 AI의 결정을 평가할 수 있도록 돕는 데 중점을 둡니다. 이는 AI 시스템이 '블랙박스'처럼 작동하여 그 결정 과정이 불투명한 문제를 해결하기 위한 접근 방식입니다.\n",
      "\n",
      "설명 가능한 AI가 중요한 이유는 다음과 같습니다:\n",
      "\n",
      "1. **신뢰 구축**: AI 시스템의 결정 과정이 명확하게 설명되면 사용자와 이해관계자들이 AI에 대한 신뢰를 가질 수 있습니다. 신뢰는 AI의 광범위한 채택과 긍정적인 사회적 영향을 위해 필수적입니다.\n",
      "\n",
      "2. **책임성**: AI의 결정이 어떻게 이루어졌는지를 이해함으로써, 개발자와 사용자 모두가 AI 시스템의 결과에 대한 책임을 질 수 있습니다. 이는 윤리적이고 책임감 있는 AI 사용을 촉진합니다.\n",
      "\n",
      "3. **편견 및 공정성**: AI 시스템이 내리는 결정이 공정한지 평가하기 위해서는 그 결정의 근거를 이해해야 합니다. XAI는 AI의 편향성을 식별하고 수정하는 데 도움을 줄 수 있습니다.\n",
      "\n",
      "4. **규제 준수**: 많은 산업에서 AI의 사용이 증가함에 따라, 규제 기관은 AI 시스템의 투명성과 설명 가능성을 요구하고 있습니다. XAI는 이러한 규제를 준수하는 데 중요한 역할을 합니다.\n",
      "\n",
      "5. **사용자 교육**: AI의 작동 방식을 이해함으로써 사용자는 AI 시스템을 보다 효과적으로 활용할 수 있으며, AI와의 상호작용에서 더 나은 결정을 내릴 수 있습니다.\n",
      "\n",
      "결론적으로, 설명 가능한 AI는 AI 시스템의 신뢰성, 책임성, 공정성을 높이고, 사용자와 사회에 긍정적인 영향을 미치는 데 필수적인 요소입니다.\n",
      "\n",
      "=== STARTING STANDARD TOP-K RETRIEVAL ===\n",
      "Query: '설명 가능한 AI(Explainable AI)'란 무엇이며, 왜 중요한가?\n",
      "문서에서 텍스트를 추출 중...\n",
      "텍스트를 중첩 없이 청크 단위로 분할 중...\n",
      "21개의 청크가 생성되었습니다.\n",
      "청크 임베딩을 생성 중...\n",
      "Creating query embedding and retrieving chunks...\n",
      "관련 세그먼트를 문맥으로 활용하여 응답을 생성합니다...\n",
      "\n",
      "=== FINAL RESPONSE ===\n",
      "설명 가능한 AI(Explainable AI, XAI)는 AI 시스템의 의사 결정 과정을 더 투명하고 이해하기 쉽게 만드는 것을 목표로 하는 기술입니다. XAI는 AI 모델이 어떻게 결정을 내리는지에 대한 인사이트를 제공하여 사용자가 AI의 신뢰성과 공정성을 평가할 수 있도록 돕습니다. 이는 특히 딥러닝 모델과 같은 복잡한 AI 시스템에서 중요한데, 이러한 모델은 종종 '블랙박스'처럼 작동하여 그 내부 작용을 이해하기 어렵기 때문입니다.\n",
      "\n",
      "설명 가능한 AI의 중요성은 다음과 같습니다:\n",
      "\n",
      "1. **신뢰 구축**: 사용자가 AI 시스템의 결정을 이해하고 평가할 수 있도록 함으로써, AI에 대한 신뢰를 구축하는 데 기여합니다. 신뢰는 AI 시스템의 채택과 사용에 있어 필수적입니다.\n",
      "\n",
      "2. **책임감 향상**: AI의 결정 과정이 명확해지면, 그 결과에 대한 책임을 명확히 할 수 있습니다. 이는 AI 시스템의 개발자와 사용자 모두에게 윤리적 책임을 부여합니다.\n",
      "\n",
      "3. **편향성 해결**: AI 시스템이 내리는 결정이 공정하고 차별적이지 않도록 하기 위해, 그 결정 과정의 투명성을 높이는 것이 중요합니다. 설명 가능한 AI는 편향성을 식별하고 해결하는 데 도움을 줄 수 있습니다.\n",
      "\n",
      "4. **규제 준수**: 많은 산업에서 AI 시스템의 투명성과 설명 가능성을 요구하는 규제가 증가하고 있습니다. XAI는 이러한 규제를 준수하는 데 필수적인 요소입니다.\n",
      "\n",
      "결론적으로, 설명 가능한 AI는 AI 시스템의 신뢰성, 책임성, 공정성을 높이는 데 중요한 역할을 하며, 이는 AI 기술의 지속 가능한 발전과 사회적 수용을 촉진하는 데 기여합니다.\n",
      "\n",
      "=== 응답 비교 평가 ===\n",
      "기준 정답과 비교하여 응답 평가 중...\n",
      "\n",
      "=== 평가 결과 ===\n",
      "1. **더 정확하고 포괄적인 응답은 무엇인가요?**\n",
      "   - **응답 평가**: 두 응답 모두 설명 가능한 AI의 개념 및 중요성을 잘 설명하고 있지만, [Standard Retrieval Response]가 더 정확하고 포괄적입니다. 이 응답은 설명 가능한 AI의 정의뿐만 아니라 결정 과정의 투명성 문제, 사용자 신뢰, 책임성, 편향성 해결, 규제 준수 등 다양한 측면을 포함하여 설명하였습니다. 반면, [Relevant Segment Extraction Response]는 유사한 내용을 담고 있으나 다소 간략하고 추가적인 논점 (사용자 교육 등)을 언급하지 않았습니다.\n",
      "   - **결론**: [Standard Retrieval Response]\n",
      "\n",
      "2. **사용자 질문을 더 잘 해결한 응답은 어떤 것인가요?**\n",
      "   - **응답 평가**: [Standard Retrieval Response]가 사용자 질문에 대한 해결이 더 우수합니다. 이 응답은 설명 가능한 AI의 개념을 명확하게 설명하고, 그 중요성을 여러 측면에서 구체적으로 나열하여 질문에 대한 포괄적이고 깊은 이해를 제공합니다. \n",
      "   - **결론**: [Standard Retrieval Response]\n",
      "\n",
      "3. **불필요하거나 관련 없는 정보를 덜 포함한 응답은 무엇인가요?**\n",
      "   - **응답 평가**: 두 응답 모두 관련된 정보를 포함하지만, [Relevant Segment Extraction Response]는 다소 간략하여 불필요한 정보가 적고 핵심에 집중하고 있습니다. 반면, [Standard Retrieval Response]는 더 포괄적인 데이터를 제공하기 때문에 상대적으로 길고 다양합니다. 그러나 이 길이가 정보의 질을 저하시키지 않으므로 둘 다 유용합니다.\n",
      "   - **결론**: [Relevant Segment Extraction Response] (불필요한 정보가 적음)\n",
      "\n",
      "**종합 평가**\n",
      "- [Standard Retrieval Response]는 보다 포괄적이고 깊이 있는 설명을 제공하므로, 사용자 질문에 대한 해결이 더 효과적이며, 정확한 정보를 담고 있습니다. 반면 [Relevant Segment Extraction Response]는 간결하지만 핵심 내용을 더 다루지 못합니다. \n",
      "- 따라서, 설명 가능한 AI에 대한 질문에 대한 더 나은 응답은 [Standard Retrieval Response]입니다.\n"
     ]
    }
   ],
   "source": [
    "# 검증용 JSON 파일에서 데이터 로드\n",
    "with open('dataset/validation.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 첫 번째 테스트 케이스의 질의 추출\n",
    "query = data[0]['question']\n",
    "\n",
    "# 참조 정답(ideal_answer) 추출\n",
    "reference_answer = data[0]['ideal_answer']\n",
    "\n",
    "# 사용할 PDF 문서 경로\n",
    "pdf_path = \"dataset/AI_Understanding.pdf\"\n",
    "\n",
    "# 두 가지 RAG 방식(RSE vs Standard Top-K)에 대한 평가 실행\n",
    "results = evaluate_methods(pdf_path, query, reference_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
